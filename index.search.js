var relearn_search_index = [
  {
    "breadcrumb": "Example",
    "content": "last modified: 2024-01-11 by Kodai Okawa This is from ANAROOT source (https://rnc.riken.go.jp/RIBFDAQ/index.php?Tools%2FAnalysis%2FANAROOT%2FInstallation)\n​ anaroot/sources/Core/include/segidlist.h anaroot/sources/Core/include/segidlist.h // Module 0--255 static const int C16 = 0; static const int C24 = 1; static const int AD413AC = 2; // AD413A + w/o Zero supp. (CAMAC read) static const int AD413ACZ = 3; // AD413A + Zero suppression (CAMAC read) static const int AD413AM = 4; // AD413A + w/o Zero supp. + Memory static const int AD413A = 5; // AD413A + Zero suppression + Memory static const int AD413AMZ = 5; // AD413A + Zero suppression + Memory static const int L3377 = 6; // LeCroy 3377 Double word (CAMAC read) static const int L3377CW = 6; // LeCroy 3377 Double word (CAMAC read) static const int L3377CS = 7; // LeCroy 3377 Single word (CAMAC read) static const int C32 = 8; // C32 such as SIS32XX series static const int P7166 = 9; // Philips 7166 + w/o Zero supp. static const int P716X = 9; // Philips 7166 + w/o Zero supp. static const int P716XZ = 10; // Philips 7166 + Zero suppression static const int CTM405 = 11; static const int L4300BC = 11; // LeCroy 4300B + w/o Zero supp. (CAMAC read) static const int L4300BCZ = 12; // LeCroy 4300B + Zero suppression (CAMAC read) static const int L4300BM = 13; // LeCroy 4300B + w/o Zero supp. + Memory static const int L4300BMZ = 14; // LeCroy 4300B + Zero suppression + Memory static const int UNDEFINE15 = 15; static const int L3377MW = 16; // LeCroy 3377 Double word + Memory static const int L3377MS = 17; // LeCroy 3377 Single word + Memory static const int UNDEFINE18 = 18; static const int MDPP19 = 19; // Mesytech MDPP-19 static const int UNDEFINE20 = 20; static const int V775 = 21; static const int V785 = 21; static const int V792 = 21; static const int V550 = 22; static const int V767 = 23; static const int V1190 = 24; static const int V1190A = 24; static const int V1190B = 24; static const int V1290 = 25; static const int V1190C = 26; static const int V7XXBIGEND = 27; static const int NEULANDTS = 28; static const int DSP = 29; static const int V1740 = 30; static const int A3100 = 31; static const int MADC32 = 32; // Mesytech ADC static const int MQDC32 = 33; // Mesytech QDC static const int MTDC32 = 34; // Mesytech TDC static const int UNDEFINE35 = 35; static const int AMTTDC = 36; static const int SIS3301 = 37; static const int LUPOIO = 41; static const int LUPOTS = 42; static const int LUPOMTS = 43; // for dead time monitor static const int MUST2VXI = 50; static const int MINOS = 53; static const int TACQUILA = 54; static const int A3400 = 55; ",
    "description": "",
    "tags": [],
    "title": "Segment ID",
    "uri": "/artemis_crib/example/segid/index.html"
  },
  {
    "breadcrumb": "Example \u003e Offline analysis",
    "content": "last modified: 2023-12-15 by ",
    "description": "",
    "tags": [],
    "title": "New processors",
    "uri": "/artemis_crib/example/offline_analysis/new_processor/index.html"
  },
  {
    "breadcrumb": "Example \u003e Online analysis",
    "content": "last modified: 2024-01-20 by Kodai Okawa From here, we would like to explain in detail how to analyze the actual experiment. We assume that you have already prepared your the analysis environment. It is okay either your own directory or the default directory (see CRIB configuration). If you are not ready yet, please see here.\nSo let’s start to check the data. At the F1 focal plane, there is (charge-divition) PPAC. The steering file to analyze f1 data is chkf1.yaml.\nsteering/chkf1.yaml We usually use “chk” (check) as a prefix of the steering files to analyze from raw binaly data.\n$ artlogin (username) $ a artemis [0] add steering/chkf1.yaml NAME=hoge NUM=0000 artemis [1] resThe important data is “X position” at the F1PPAC. The histogram can be check by following step:\nartemis [2] sus artemis [3] ls artemis \u003e 0 art::TTreeProjGroup f1check f1_check 1 art::TAnalysisInfo analysisInfo artemis [4] cd 0 artemis [5] ls f1check \u003e 0 art::TH1FTreeProj f1ppac_X f1ppac X 1 art::TH1FTreeProj f1ppac_Y f1ppac Y 2 art::TH1FTreeProj f1ppac_X1raw f1ppac X1raw 3 art::TH1FTreeProj f1ppac_X2raw f1ppac X2raw 4 art::TH1FTreeProj f1ppac_Y1raw f1ppac Y1raw 5 art::TH1FTreeProj f1ppac_Y2raw f1ppac Y2raw 6 art::TH2FTreeProj f1ppac_x_y f1ppac X vs Y 7 art::TH2FTreeProj f1ppac_x_rf f1ppac X vs RF 8 art::TH2FTreeProj f1ppac_x1_x2 f1ppac x1 vs x2 9 art::TH2FTreeProj f1ppac_y1_y2 f1ppac y1 vs y2Many histograms are defined, but in practice it’s enough to check the first X position. Sometimes we check other raw data histograms to see if the behavior of F1PPAC is correct or not.\nartemis [6] ht 0Usually a gaussian fit is performed to get center the position.\nartemis [7] xfFor the commane “xf” (xfitg), please check here.\nWhen you think the signals from F1PPAC is okay, but position seems wrong (the X position is different from the setting of F1 slit), pleace modify the parameter files.\nprm/ppac/ch2q.prm prm/ppac/f1ppac.yaml It is actually charge-divition PPAC, but the structure of parameter file is the same with dl-PPAC, so please also check PPAC preparation.\n",
    "description": "",
    "tags": [],
    "title": "F1",
    "uri": "/artemis_crib/example/online_analysis/f1/index.html"
  },
  {
    "breadcrumb": "Example \u003e Preparation",
    "content": "last modified: 2023-12-13 by Kodai Okawa I would now like to introduce the actual analysis using the CRIB analysis server. There are two ways to enter the analysis server, directly or remotely via ssh. If you come to CRIB and operate the server directly, I think it is quicker to analyse using the server while asking the CRIB members directly as I think they are nearby.\n1. SSH configuration To enter the CRIB server, you need to enter the CNS network. To do this, you need to create an account on the CNS login server. Please contact Okawa (okawa@cns.s.u-tokyo.ac.jp) or the person responsible for CRIB (see here) and tell us that you want a login server account.\nThe CNS login server uses public key cryptography, so you need to send a shared key when you apply. This section describes how to create the key, especially on MacOS.\ncd # move to /Users/yourname/ (home directory) mkdir .ssh # if there is no .ssh directory cd .ssh ssh-keygenYou will be asked a number of interactive questions after this command, all of which are fine by default (Enter). Then you will see the pair of public-key and private-key.\nls id_rsa id_rsa.pubid_rsa is the private-key, and id_rsa.pub is the public-key. The private key is important for security reasons and should be kept on your own computer. Then, please send this public-key to the CNS member. in MacOS, open . command will open a finder for that directory, so it is easy to attach it to an email from here. In the email,\nyour fullname (affiliation) username attached public-key are needed.\nNext, let’s set up multi-stage ssh. As the login server is just a jump server, it is useful to be able to ssh to the CRIB analysis server at once! So create the following config file. The file placed in this directory is automatically read when you ssh.\ncd ~/.ssh vi config ​ ~/.ssh/config ~/.ssh/config 1Host login 2 HostName CNS_loginserver_hostname 3 User username 4 IdentityFile ~/.ssh/id_rsa 5 ForWardX11Timeout 24h 6 ControlPersist 30m 7 ForwardAgent yes 8 ControlMaster auto 9 ControlPath ~/.ssh/mux-%r@%h:%p 10 11# any name is okay 12Host cribana 13 HostName analysisPC_hostname 14 User crib 15 IdentityFile ~/.ssh/id_rsa 16 ProxyCommand ssh login nc %h %p 17 ForwardAgent yes 18 ControlMaster auto 19 ControlPath ~/.ssh/mux-%r@%h:%p 20 ControlPersist 30m You will be informed of the second and third lines above that we highlighted, so please change this parts. And ask the IP address of the CRIB analysis PC to the CRIB member, and change the 13 line.\nThen you can enter the CRIB analysis PC just by\nssh cribanaCRIB member will tell you the passward!\nFor the VNC server (local forwarding), please see this section.\n2. your artemis configuration When you enter the CRIB computer, please check this is zsh shell.\n\u003e echo $SHELL /usr/local/bin/zsh Info Currently, zsh installed locally is used. It is planned to update the OS in the future, after which it will differ from this path in the future.\nIf it is not zsh (like bash), please command\n\u003e zshThen you can start to configure by\n\u003e artlogin yourname # input your information... \u003e mkdir build \u003e cd build \u003e cmake .. \u003e make -j4 \u003e make install \u003e acdFor the detail, please check here.\n3. basic usage start artemis \u003e acd # move to your artemis work directory \u003e a # start artemis! \u003e a macro/macro.C # run macro script important command in the artemis console # read steering file artemis [*] add steering/hoge.yaml NAME=hoge NUM=0000 # start event loop artemis [*] res artemis [*] start # defined in CRIB artemis # stop event loop artemis [*] sus artemis [*] stop # defined in CRIB artemis # help artemis [*] help # quit from artemis artemis [*] .q commands for checking histograms # check and move the directory artemis [*] ls artemis [*] cd 0 # cd ID # move to home directory in artemis artemis [*] cd # cd .. will work? # draw the histograms artemis [*] ht 0 colz # ht ID option artemis [*] hn colz # draw the next histogram object artemis [*] hb colz # draw the previous histogram object # divide the canvas artemis [*] zone 2 2 # 2 x 2 canvas # save and print the canvas artemis [*] sa artemis [*] pri analize using TTree # check the files artemis [*] fls # move to the created ROOT file artemis [*] fcd 0 # fcd fileID # check the all branches artemis [*] br # check the data members or methods artemis [*] br branchname # ex. artemis [1] br ppaca # the name of TTree object is \"tree\" (actually TArtTree object) artemis [*] tree-\u003eDraw(\"ppaca.fY:ppaca.fX\u003e\u003eppaca(100,-20.,20., 100,-20.,20.)\",\"\",\"colz\")See here for an example using random numbers.\n",
    "description": "",
    "tags": [],
    "title": "Basic",
    "uri": "/artemis_crib/example/preparation/basic/index.html"
  },
  {
    "breadcrumb": "CRIB Configuration",
    "content": "last modified: 2023-12-12 by Kodai Okawa CRIB shares the analysis environment of all experiments under one user account (username crib). Therefore, when you want to check data from an old experiment or when several people are analysing the data, you need to log in to the same user account.\nOf course, the analysis environment varies according to the experiment (and even different environments for different users within the same experiment!) and these have to be managed well. The “.bashrc/.zshrc” and “artlogin (artlogin2)” commands set them up. Currently we are using “zsh (.zshrc)”.\nExperimental environment ​ .bashrc/.zshrc .bashrc/.zshrc export EXP_NAME=\"current\" # your experiment export EXP_NAME_OLD=\"previous\" # old experiment The EXP_NAME is current experiment and you can enter the environment by using artlogin command. At the same time, the EXP_NAME_OLD is the old experiment and you can use artlogin2 command.\nIn the current version, we support two experimental environment and if you want to check other experimental data, please change EXP_NAME_OLD.\nWarning When you modify “.bashrc/.zshrc”, all people’s settings will change. Therefore please do not change EXP_NAME as much as possible, because we want to set this environment variable as the active experiment. If you change this, please report it so that CRIB members are aware of it.\nInfo Commands may be created in the future to enter the environment of all experiments flexibly, not just two. (like artoldlogin {expname} {username}?)\nThen you can enter the different analysis environment like this:\n\u003e artlogin (username) \u003e artlogin2 (username)User environment CRIB uses a default user as well as individual analysis environments. The username of the default user is the same with experiment name.\nIf you set the name of the experiment to “si26a” (EXP_NAME), then the username “si26a” will be the default user. The user’s environment can be entered with the “artlogin” command with no arguments.\n\u003e artlogin \u003e pwd /home/crib/art_analysis/si26a/si26aIf you want to test something by changing files, or if you want to use your own VNC server, you can enter that environment by specifying its name as an argument.\n\u003e artlogin okawa # if this is the first time to command, you will see setup comments. \u003e pwd /home/crib/art_analysis/si26a/okawa Warning When using the default user, try to avoid using a VNC server (do not create .vncdisplay files). The main reason for creating a default user is to analyse locally (for shifters) in the online analysis, and using a VNC server makes it impossible to view the figures locally.\nDirectory structure The directory structure comprising artemis is as follows. (The location of artemis itself is omitted).\n\u003e tree -L 2 ~/art_analysis /home/crib/art_analysis ├── current # accessed by \"artlogin\" │ ├── current # default user │ └── okawa # individual user ├── previous # accessed by \"artlogin2\" │ ├── previous │ └── okawa ├── old1 │ ├── old1 │ └── okawa └── old2 # -- snip --",
    "description": "",
    "tags": [],
    "title": "Analysis environment",
    "uri": "/artemis_crib/crib_parts/environment/index.html"
  },
  {
    "breadcrumb": "Setting",
    "content": "last modified: 2023-11-05 by Kodai Okawa If you installed with “curl” command explained previous chapter, you should have artnew command. This command will make new experiment directory interactively.\nBefore using this command, please check and make the directory structure!\nrawdata directory (like /mnt/data or /data? Create it to suit your situation.) output rootfile directory (like /data/art_output?) git repository local repository: suit for online analysis remote repository: suit for offline analysis Let’s start “artnew” command! The word after “:” is your input.\n\u003e artnew Input the experiment name create new artemis work directory? (y/n): y Input experimental name: test Is it OK? (y/n): y Input value: test Check the base directory (default value is fine!) If there are no input, the default value will be used. artnew: If no input is provided, the default value is used. Input repository path or URL (default: https://github.com/okawak/artemis_crib.git): Is it OK? (y/n): y Input value: https://github.com/okawak/artemis_crib.git Input the rawdata directory Input rawdata directory path (default: /data/test/ridf): Is it OK? (y/n): y Input value: /data/test/ridf Input the output directory Input output data directory path (default: /data/test/user): Is it OK? (y/n): y Input value: /data/test/user Input the git setting (PLEASE MAKE your own repository. Local repository will be fine) Based on the repository, do you make your own repository? (y/n): y is it local repository (y/n): y artnew: making LOCAL repository of test Input the local repository path (default: $HOME/repos/exp): Is it OK? (y/n): y Input value: /home/crib/repos/exp -- snip -- art_analysis setting for test is finished!The initial setting is completed!!\n",
    "description": "",
    "tags": [
      "CRIB"
    ],
    "title": "New experiment",
    "uri": "/artemis_crib/setting/new_experiment/index.html"
  },
  {
    "breadcrumb": "Installation",
    "content": "last modified: 2023-11-02 by Kodai Okawa The following machines have been tested for operation.\n1. Writer’s (Okawa’s) machine Almalinux 9.2 zsh 5.8 gcc 11.3.1 cmake 3.20.2 ROOT 6.28/04 yaml-cpp 0.7.0 2. CRIB’s analysis machine CentOS Linux release 7.9.2009 (Core) zsh 5.5.1 gcc 9.3.1 (using devtoolset-9) cmake 3.28 (install manually) ROOT 6.28/06 yaml-cpp 0.8.0 NOTE:\nFrom 2023/10, Ubuntu system is also avaliable. (issue48) Scripts for some automate operation are written in zsh format. Installation seems to be difficult on macOS (because of clang not gcc) in the current version. ",
    "description": "",
    "tags": null,
    "title": "Requirements",
    "uri": "/artemis_crib/installation/requirements/index.html"
  },
  {
    "breadcrumb": "",
    "content": "This chapter describes how to set up the artemis environment for the CRIB experiment.\nRequirements cmake ROOT yaml-cpp artemis mount setting energyloss calculator art_analysis ",
    "description": "",
    "tags": null,
    "title": "Installation",
    "uri": "/artemis_crib/installation/index.html"
  },
  {
    "breadcrumb": "Example \u003e Online analysis",
    "content": "last modified: 2024-01-20 by Kodai Okawa In the F2 focal plane, we check the secondary beam condition. In other words, identify the beam particles we want and adjust the beamline parameters to get the most amount of the beam particle. Therefore, we need to identify the beam ion from the data. To do so, we perform simulation.\nThis is almost the same with this web application. This web application uses enewz energy loss calculation, but PID using artemis uses SRIM.\nThese are the source code for the PID calculation.\nTCRIBPIDProcessor.cc TCRIBPIDProcessor.h Principles The simple principle of PID (Particle IDentification) is described.\nFirst, the energies of the various beam ions are determined from the value of the magnetic rigidity ( $B\\rho$) of the dipole magnets. The values are then calculated using relativity.\n$$ m_0\\gamma\\frac{v^2}{\\rho} = qevB $$ $$ B\\rho = \\frac{m_0\\gamma\\beta c}{qe} $$ $$ \\frac{B\\rho qe}{c} = m_0\\frac{\\beta}{\\sqrt{1-\\beta^2}} $$From this equation, solving for $\\beta^2$,\n$$ \\beta^2 = \\frac{1}{1+\\left( \\frac{m_0 c}{B\\rho qe} \\right)^2} $$ $$ \\frac{1}{\\sqrt{1-\\beta^2}} = \\sqrt{1+\\left( \\frac{B\\rho qe}{m_0 c} \\right)^2} $$Relativistic energy $E$ is\n$$ E = \\frac{m_0 c^2}{\\sqrt{1-\\beta^2}} $$ $$ E^2 = \\left(m_0 c^2\\right)^2 + \\left( B\\rho qec \\right)^2 $$Therefore, from this equation, $E$ can be obtained from $B\\rho$ and the kinetic energy can be derived from the following relationship.\n$$ E = E_{kin} + m_0 c^2 $$ $$ E_{kin} = m_0 c^2\\left( \\sqrt{1+\\left( \\frac{B\\rho qec}{m_0 c^2} \\right)^2} -1 \\right) $$The equation for determining velocity from energy using relativity can also be obtained as follows.\n$$ E_{kin} + m_0 c^2 = \\frac{m_0 c^2}{\\sqrt{1-\\left(\\frac{v}{c}\\right)^2}} $$ $$ v = c\\sqrt{1-\\left( \\frac{1}{\\frac{E_{kin}}{m_0 c^2} +1} \\right)^2} $$The energy loss of the detector placed on the beamline is then calculated and the PID diagram is obtained by plotting the possible measured values using these relationships.\nUsage First, please prepare the SRIMlib dataset. You need all input ion for “mylar” and “Si” target energy loss table. For the SRIMlib setting, please refer this page.\nNext, you need input ions and beamline parameter files. The format is like this.\n​ prm/pid/expname.yaml prm/pid/expname.yaml input_ions: - name: 7Li3 charge: 3 mass: 7.01435758 # amu color: 0 # 0 -\u003e red, 1 -\u003e blue, 2 -\u003e black - name: 6He2 charge: 2 mass: 6.01778863 color: 1 - name: 3H1 charge: 1 mass: 3.015500905 color: 2 - name: 2H1 charge: 1 mass: 2.013553496 color: 2 - name: 1H1 charge: 1 mass: 1.007276452 color: 2 - name: 4He2 charge: 2 mass: 4.001506094 color: 2 # BLD parameters f1_parameters: brho: 1.227 # Tm rf_period: 57.0 # ns f2_parameters: PPAC_thickness: 10.0 # um, mylar SSD_thickness: 1500.0 # um f3_parameters: a_thickness: 15.0 # um, mylar, PPACa/MWDCa b_thickness: 15.0 # um, mylar, PPACb/MWDCb distance: 290.5 # mm, between two tracking detectors trigger: 0 # PPACa/MWDCa -\u003e 0, PPACb/MWDCb -\u003e 1 # display parameters f2_display: rf_offset: -6.5 # ns rf_range: [0.0, 120.0] # ns energy_range: [0.0, 100.0] # MeV f3_display: rf_offset: -12.0 # ns tof_offset: -2.7 # ns rf_range: [0.0, 120.0] # ns tof_range: [0.0, 8.0] # ns Info You can add the beam ions freely, but you need to prepare SRIM Output table.\nLastly, let’s prepare the steering file. If you want to do only PID calculation, you can use chkpid.yaml.\n​ steering/chkpid.yaml steering/chkpid.yaml Processor: - name: pid type: art::TCRIBPIDProcessor parameter: FileName: prm/pid/expname.yaml Batch: false OutputTransparency: 1 You can add these sentences for any other steering files. I think it is useful when you want to overlap the data figure and calculation figure. If you set Batch: false, the canvases for F2 PID and F3 PID will appear automatically. Batch: true is quiet mode.\nThis is an example of the automatically generated figure.\nThe process for the calculation is performed in init process (I mean not event loop), so when you add the steering file, the figure will be created.\n\u003e acd \u003e a artemis [0] add steering/chkpid.yaml # process is performed now # if Batch: false, the two PID figure will appear automatically artemis [1] ls artemis \u003e 0 TDirectory pid pid artemis [2] cd 0 artemis [3] ls pid \u003e 0 TMultiGraph F2_PID; F2 RF [ns]; F2 SSD [MeV] 1 TMultiGraph F3_PID; F3 RF [ns]; PPACs/MWDCs TOF [ns] 2 TCanvas F2_canvas F2_canvas 3 TCanvas F3_canvas F3_canvas artemis [4] draw 0 Info There are two kinds of object, TMultiGraph and TCanvas. The ht command cannot draw these object, so I also made draw command to be able to draw “TMultiGraph” objects.\nHOWEVER, even this “draw” command cannot display the “TCanvas” object yet… If you save the object using hstore command or check from THttpServer, you can check the TCanvas objects.\nThis “TMultiGraph” object is useful when you want to overlay th data.\nartemis [*] ht something # this is gaussian example artemis [*] dr 0 p same ",
    "description": "",
    "tags": [],
    "title": "Beam PID",
    "uri": "/artemis_crib/example/online_analysis/pid/index.html"
  },
  {
    "breadcrumb": "Example \u003e Preparation",
    "content": "last modified: 2023-12-15 by Kodai Okawa CRIB uses a multi-hit TDC called V1190 to take timing data (manual). When a trigger comes into this module, it opens a window with a set time width and records the timing of the data.\nHowever, even if the signal is sent at exactly the same time to the trigger, due to the uncertainty in opening that window, the resulting channel will vary. Since absolute channel values will vary, but relative channel values for a given (especially trigger) timing will remain the same, it is necessary to subtract all data by some reference channel to achieve good timing resolution.\nThe signal that serves as the reference for that time is what we call Tref! (Time reference) Since it is essential that all events contain that data, we put the trigger signal in one of the channels and make it a Tref.\nThe “tref” settings are made in the following file:\n​ steering/tref.yaml steering/tref.yaml Processor: # J1 V1190A - name: proc_tref_v1190A_j1 type: art::TTimeReferenceProcessor parameter: # [[device] [focus] [detector] [geo] [ch]] RefConfig: [12, 2, 7, 0, 15] SegConfig: [12, 2, 7, 0] Parameters RefConfig and SegConfig are set using the same ID as in the map file.\nThe “RefConfig” represents the “Tref” signal and the “SegConfig” represents the V1190 module. Therefore, the role of the processor is to subtract the “Segconfig” V1190 all timing signal from the “RefConfig” tref signal.\nTo apply this processor, add the following line to the steering file. For example,\n​ steering/chkf3.yaml steering/chkf3.yaml Anchor: - \u0026input ridf/@NAME@@NUM@.ridf - \u0026output output/chkf3@NAME@@NUM@.root - \u0026histout output/chkf3@NAME@@NUM@.hist.root Processor: - name: timer type: art::TTimerProcessor - name: ridf type: art::TRIDFEventStore parameter: OutputTransparency: 1 InputFiles: - *input - name: mapper type: art::TMappingProcessor parameter: OutputTransparency: 1 - include: tref.yaml - include: rf/rf.yaml - include: coin/coin.yaml - include: ppac/dlppac.yaml - include: ssd/f3ssd.yaml - name: outputtree type: art::TOutputTreeProcessor parameter: FileName: - *output Note The tref.yaml should be written before the main processor. In this example, it is written right after TMappingProcessor, and we recommend writing it in this position.\n",
    "description": "",
    "tags": [],
    "title": "Tref for V1190",
    "uri": "/artemis_crib/example/preparation/tref/index.html"
  },
  {
    "breadcrumb": "CRIB Configuration",
    "content": "last modified: 2023-12-12 by Kodai Okawa We often use “nssta” (non-save mode start) analysis in the beam tuning. It is not necessary to take data, but we need to check the beam condition by using artemis. In this case, TRIDFEventStore can be used as online mode.\nBy default, if we don’t add an input file name and set the SHMID (Shared Memory ID), artemis will use online mode. However, it is necessary to use different types of steering files, one for use in online-mode and the other for use from a file, which can be complicated…\nTherefore, the same steering file was changed to automatically go online mode when the ridf file was not present.\n# from ridf files artemis [0] add steering/hoge.yaml NAME=hoge NUM=0000# online-mode artemis [0] add steering/hoge.yaml # no argumentTo achieve this, the original file was changed as follows.\n​ artemis/sources/loop/ridf/TRIDFEventStore.cc artemis/sources/loop/ridf/TRIDFEventStore.cc 129 for (Int_t i=0; i!=n;i++) { 130 printf(\"file = %s\\n\",fFileName[i].Data()); 131+ if(!gSystem-\u003eFindFile(\".\", fFileName[i])) { 132+ Info(\"Init\", \"No input file -\u003e Online mode\"); 133+ fIsOnline = kTRUE; 134+ } 135 } steering file We always use SHMID=0, so it works simply by adding the following sentence.\n- name: ridf type: art::TRIDFEventStore parameter: OutputTransparency: 1 InputFiles: - *input SHMID: 0",
    "description": "",
    "tags": [
      "CRIB"
    ],
    "title": "Online-mode analysis",
    "uri": "/artemis_crib/crib_parts/onlinemode/index.html"
  },
  {
    "breadcrumb": "Setting",
    "content": "last modified: 2023-11-05 by Kodai Okawa After artnew command, you can see new directory of config files.\n\u003e tree -a art_analysis art_analysis ├── .conf │ ├── artlogin.sh +│ └── test.sh ├── bin │ ├── art_check │ ├── art_setting │ └── artnew +└── test This is experiment name “test” example. In order to load this script test.sh, please modify “EXP_NAME” environment valiable in .zshrc.\n​ .bashrc/.zshrc .bashrc/.zshrc export EXP_NAME=\"test\" # your experiment And load the config file.\n\u003e source ~/.zshrcThen you can make your own work directory by using artlogin command!\nLet’s start “artlogin” command! For example, let’s make default user (user name is the same with experiment name)!\n\u003e artloginIf you want to make your own directory, the following will work.\n\u003e artlogin yourname Check if you really want to make your work directory artlogin: user 'test' not found. create new user? (y/n): y Cloning into '/Users/okawa/art_analysis/test/test'... done. Git setting artlogin: making local git config Input fullname: KodaiOkawa Is it Okay? (y/n): y Input email address: okawa@cns.s.u-tokyo.ac.jp Is it Okay? (y/n): y Symbolic link setting. If there are no problem, the current directory move to your artemis work directory \u003e pwd /home/crib/art_analysis/test/test \u003e ls -lIf your synbolic link seems okay, the setting is all!\nIf artnew setting have problem, the error message will appear. Typical examples are as follows.\nmkdir: /data: Read-only file systemThis is a case of the directory permissions not being set correctly. Use the chmod command or similar to set them correctly and try again.\n",
    "description": "",
    "tags": [
      "CRIB"
    ],
    "title": "New user",
    "uri": "/artemis_crib/setting/new_user/index.html"
  },
  {
    "breadcrumb": "Installation",
    "content": "last modified: 2023-11-02 by Kodai Okawa Generally, dnf install cmake or brew install cmake support latest version of the cmake, but for some older machine like CentOS7, it is too old to install ROOT.\nThe latest ROOT require CMake 3.16 or higher, and if your system doesn’t support this version, you need to install manually.\nYou can get more information from here.\ncd hoge git clone https://github.com/Kitware/Cmake.git cd Cmake ./bootstrap make -j8 sudo make installIf you want to set the version, you can change the branch (tag). The default branch is master.\n",
    "description": "",
    "tags": [],
    "title": "cmake",
    "uri": "/artemis_crib/installation/cmake/index.html"
  },
  {
    "breadcrumb": "",
    "content": "This chapter describes how to prepare the configuration file for the experiment. If you have already some CRIB artemis environment, please see from here for initial settings.\nNew experiment New user Build artemis commands Map configuration Steering Histograms VNC server ",
    "description": "",
    "tags": null,
    "title": "Setting",
    "uri": "/artemis_crib/setting/index.html"
  },
  {
    "breadcrumb": "Example \u003e Online analysis",
    "content": "last modified: 2024-01-20 by Kodai Okawa The basic usage is the same.\nWe use this steering file to check F2 data.\nsteering/chkf2.yaml $ artlogin (username) $ a artemis [0] add steering/chkf2.yaml NAME=hoge NUM=0000 artemis [1] res artemis [2] sus artemis [3] ls artemis \u003e 0 art::TTreeProjGroup f2check f2_check 1 art::TAnalysisInfo analysisInfoartemis [4] cd 0 artemis [5] ls f2check \u003e 0 art::TH1FTreeProj f2PPAC X f2ppac x 1 art::TH1FTreeProj f2PPAC Y f2ppac y 2 art::TH1FTreeProj f2SSD raw f2ssd raw 3 art::TH1FTreeProj f2SSD raw (low) f2ssd raw (low) 4 art::TH1FTreeProj f2SSD cal f2ssd cal 5 art::TH2FTreeProj f2PPAC X vs Y f2ppac X vs Y 6 art::TH2FTreeProj F2PPAC X vs RF0 f2ppac X vs rf0 7 art::TH2FTreeProj F2PPAC Y vs RF0 f2ppac Y vs rf0 8 art::TH2FTreeProj RF0 vs F2SSD raw rf0 vs f2ssd raw 9 art::TH2FTreeProj RF0 vs F2SSD cal rf0 vs f2ssd cal 10 art::TH2FTreeProj RF1 vs F2SSD cal rf1 vs f2ssd cal 11 art::TH2FTreeProj F2PPAC X vs F2SSD raw f2ppac x vs f2ssd raw 12 art::TH2FTreeProj F2PPAC X vs F2SSD cal f2ppac x vs f2ssd cal 13 art::TH2FTreeProj F2PPAC Y vs F2SSD cal f2ppac y vs f2ssd cal 14 art::TH1FTreeProj RF0 rf0As you know, you can check the histograms\n# for 1D histograms artemis [*] ht [id] artemis [*] hn # histogram next artemis [*] hb # histogram before (back?) # for 2D histograms artemis [*] ht [id] colz # colz is option artemis [*] hn colz artemis [*] hb colzIf you want to save,\nartemis [*] sa artemis [*] pri",
    "description": "",
    "tags": [],
    "title": "F2",
    "uri": "/artemis_crib/example/online_analysis/f2/index.html"
  },
  {
    "breadcrumb": "Example \u003e Preparation",
    "content": "last modified: 2023-12-18 by Kodai Okawa CRIB use two kinds of PPAC (Parallel-Plate Avalanche Counter), charge division method or delay-readout method. The PPAC placed at the F1 focal plane is charge-devision type, and the parameters to be converted to position are fixed and do not need to be calibrated. Therefore we explain the calibration method for delay-line PPAC (dl-PPAC).\nPrinciples Here we briefly describe the principle of converting from the obtained signal to position, but for more details, see here1.\nWe will discuss the x-direction because x and y is exactly same. First, define the parameters as follows\n$k_x$ : convert from signal time difference to position [mm/ns] $T_{X1},~T_{X2}$ : time at both ends of delay-line, measured at TDC [ns] $T_{Xin-offset}$ : timing offset come from inside the chamber [ns] $T_{Xout-offset}$ : timing offset come from outside the chamber [ns] (like from cabling) $X_{offset}$ : geometry offset [mm] The artemis codes calculate the X position like this formula (see TPPACProcessor.cc).\n$$ X~\\mathrm{[mm]} = k_x\\left( \\frac{T_{X1} - T_{X2} + T_{Xin-offset} - T_{Xout-offset}}{2} \\right) - X_{offset}$$ Warning Check the sign carefully! We often mistook the direction!!\nFixed parameters The $T_{X1},~T_{X2}$ are measured value by TDC, and $k_x$ and $T_{Xin-offset}$ are specific value to PPAC, so we need to care only $T_{Xout-offset}$ and $X_{offset}$. $X_{offset}$ value depends on where we put the PPAC, so what we have to do is determine the line calibration parameter ( $T_{Xout-offset}$).\nThe following is a list of dl-PPAC parameters used in CRIB experiment.\nPPAC ID $k_x$ [mm/ns] $k_y$ [mm/ns] $T_{Xin-offset}$ $T_{Yin-offset}$ #2 1.256 1.256 0.29 mm 0.18 mm #3 1.264 1.253 0.22 mm 0.30 mm #7 1.240 1.242 0.92 ns 1.58 ns #8 1.241 1.233 0.17 ns 0.11 ns #9 1.257 1.257 0.05 mm 0.04 mm #10 1.257 1.257 0.05 mm 0.04 mm Warning Different units are used for the offset. However, since the effect of this offset is eventually absorbed to the other offset value, it is no problem to use the values if we calibrate it correctly.\nParameter setting PPAC parameters are defined in the following files\nprm/ppac/dlppac.yaml For example, it is like this:\n​ prm/ppac/dlppac.yaml prm/ppac/dlppac.yaml Type: art::TPPACParameter Contents: # #7 PPAC f3bppac: # this is the name of PPAC, should be the same name with the one in steering file! ns2mm: - 1.240 - 1.242 delayoffset: - 0.92 - 1.58 linecalib: - 1.31 - -1.00 # 0: no exchange, 1: X -\u003e Y, Y -\u003e X exchange: 0 # 0: no reflect, 1: X -\u003e -X reflectx: 1 geometry: - 0.0 - 0.5 - 322.0 TXSumLimit: - -800.0 - 2000.0 TYSumLimit: - -800.0 - 2000.0 ns2mm\nThis is $k_x$ and $k_y$ parameters -\u003e input the fixed value\ndelayoffset\nThis is $T_{Xin-offset}$ and $T_{Yin-offset}$ parameters -\u003e input the fixed value\nlinecalib\nThis is explained next.\nexchange, reflectx\nThis parameter should be changed depending on the direction in which the PPAC is placed. The meanings of the parameters are given above as comments. Note CRIB takes a coordinate system such that when viewed from downstream of the beam, the x-axis is rightward and the y-axis is upward. In other words, it takes a right-handed coordinate system with the beam as the Z-axis. While looking at the actual data, change these parameters so that the coordinate system becomes this coordinate system.\ngeometry\nIn the Line calibration, please set this value to (0,0). After Line calibration, if we put the PPAC with some geometry offset, we should change this parameters. Please be careful that the parameter will add minus this value for X and Y. Z offset will be used for TPPACTrackingProcessor.\nTXSumLimit, TYSumLimit\nUsed to determine if it is a good event or not. Currently not used.\nLine calibration Before starting line calibration, please make sure that map file and steering file is correctly set. Also we need parameter file of prm/ppac/ch2ns.dat to convert TDC channel to ns unit. (already prepared I think)\ngraph LR; A[TDC channel] --\u003e|prm/ppac/ch2ns.dat| B[ns scale] B --\u003e |prm/ppac/dlppac.yaml|C{PPAC object} When you complete the setting except for linecalib parameters, let’s start calibration! We prepared two useful macros to calibrate dl-PPAC.\nmacro/run_PPACLineCalibration.C : Macro to actually execute macro/PPACLineCalibration.C : Macro that actually work First, we have to prepare the data with masks on the PPAC like following picture. This mask has holes at 12.5 mm intervals.\nThe position of the alpha line through the central hole can be calculated and the offset adjusted to achieve that position. The geometry inside the PPAC is as follows. I think all PPAC geometries used by CRIB are the same.\nThe parameters required to calculate the coordinates of the position are as follows.\nPPAC ID PPAC direction (first layer is X or Y) alpha source offset X alpha source offset Y distance between the mask and alpha source reflectx in the dlppac.yaml Using these parameters, the macro/PPACLineCalibration.C calculate the theoretical position and how much the parameters should be moved.\nExample Let’s calibrate PPACa as an example.\nPPAC ID : #2 First layer is Y alpha source offset X : 0.0 mm alpha source offset Y : 2.2 mm distance between the mask and alpha source : 92 mm reflectx : 1 (have reflection) When we set the parameter like this files, the XY figure can be obtained.\n​ prm/ppac/dlppac.yaml prm/ppac/dlppac.yaml Type: art::TPPACParameter Contents: # #2 PPAC f3appac: ns2mm: - 1.256 - 1.256 delayoffset: - 0.29 - 0.18 linecalib: - 0.0 - 0.0 exchange: 0 reflectx: 1 geometry: - 0.0 - 0.0 - -677.0 # user defined TXSumLimit: - -800.0 - 2000.0 TYSumLimit: - -800.0 - 2000.0 Then we can run the macro.\n\u003e acd \u003e vi macro/run_PPACLineCalibraion.C # please set the parameters. # instruction is written in this file \u003e a artemis [0] add steering/hoge.yaml NAME=hoge NUM=0000 artemis [1] res artemis [2] .x macro/run_PPACLineCalibration.C # -- snip -- =================================================== center position (cal) : (-0, -0.51413) center position (data) : (0.890109, -0.274066) difference : (0.890109, 0.240065) move parameters : (-1.41737, 0.382269) ===================================================And please input this value to the dlppac.yaml.\n​ prm/ppac/dlppac.yaml prm/ppac/dlppac.yaml Type: art::TPPACParameter Contents: # #2 PPAC f3appac: ns2mm: - 1.256 - 1.256 delayoffset: - 0.29 - 0.18 linecalib: - -1.417 - 0.382 exchange: 0 reflectx: 1 geometry: - 0.0 - 0.0 - -677.0 # user defined TXSumLimit: - -800.0 - 2000.0 TYSumLimit: - -800.0 - 2000.0 Then you can complete the line calibration of the PPAC.\n\u003e a artemis [0] add steering/hoge.yaml NAME=hoge NUM=0000 artemis [1] res artemis [2] .x macro/run_PPACLineCalibration.C # -- snip -- =================================================== center position (cal) : (-0, -0.51413) center position (data) : (-0.0191028, -0.571067) difference : (-0.0191028, -0.0569366) # \u003c= almost zero! move parameters : (0.0304184, -0.0906633) =================================================== Info Because of the accuracy of the fitting, it does not make much sense to move the parameters any further.\nThe PPAC is then ready to be used by measuring how much offset the beamline axis has with respect to the delay-line axis at the position where the PPAC is actually placed, and putting this into the geometry parameters.\nH. Kumagai et al., Nucl. Inst. and Meth. A 470, 562 (2001) ↩︎\n",
    "description": "",
    "tags": [],
    "title": "PPAC calibration",
    "uri": "/artemis_crib/example/preparation/ppac_calibration/index.html"
  },
  {
    "breadcrumb": "CRIB Configuration",
    "content": "last modified: 2024-01-20 by Kodai Okawa Warning still under consideration in this part!\nCRIB often wants to customise artemis because it originally used ANAPAW and wants to perform analysis like ANAPAW. However, we do not want to make too many changes to the source code of artemis itself, and we want to make it work in the user-defined part. (it means in the artemis work directory)\nIn particular, it is often the case that we want to create a new artemis command, but writing the command source on the work directory and registering it in artemislogon.C did not work somehow…\nAlso, artemislogon.C is automatically generated (from .artemislogon.C.in) by the cmake functionality, and even if this itself is changed, it will revert when cmake is redone.\nTherefore, a file called userlogon.C was prepared, which only took out the user-defined part from artemislogon.C. The following files have been modified to read this.\n​ artemis/sources/main/TArtRint.cc artemis/sources/main/TArtRint.cc 14 #include \u003cTInterpreter.h\u003e 15+#include \u003cTSystem.h\u003e 16 #include \"TLoopManager.h\" ​ artemis/sources/main/TArtRint.cc artemis/sources/main/TArtRint.cc 44 TRint::ProcessLine(\".x artemislogon.C\"); 45+ FileStat_t info; 46+ if (gSystem-\u003eGetPathInfo(\"userlogon.C\", info)==0) { 47+ TRint::ProcessLine(\".x userlogon.C\"); 48+ } If there is a userlogon.C file in the work directory, it is loaded, otherwise artemis can be used as usual.\nuserlogon.C This file can be used freely! What we wanted to do most is to register user-defined commands, which can be done as follows.\n​ userlogon.C userlogon.C { // load user function gROOT-\u003eProcessLine(\".L macro/UserUtil.C\"); // User commands register // cf definition: TCatCmdFactory *cf = TCatCmdFactory::Instance(); cf-\u003eRegister(TCatCmdLoopStart::Instance()); cf-\u003eRegister(TCatCmdLoopStop::Instance()); cf-\u003eRegister(new art::TCmdXfitg); cf-\u003eRegister(new art::TCmdXstatus); cf-\u003eRegister(new art::TCmdXYblow); cf-\u003eRegister(new art::TCmdXblow); cf-\u003eRegister(TCatCmdTCutG::Instance()); cf-\u003eRegister(new art::TCmdErase); cf-\u003eRegister(new art::TCmdDraw); // TTree merge setting TTree::SetMaxTreeSize( 1000000000000LL ); // 1TB } The first line gROOT-\u003eProcessLine(\".L macro/UserUtil.C\") load the user definition function. You can add any function to the “macro/UserUtil.C” file, and the function to load TCutG object in “/gate/*.root” directory is written defaultly. For more detail, please see tcutg command and gate pages.\n(For some reason, an error occurred when writing in artemislogon.C.) You can also customise it in other ways to make it easier for you. For example, when creating a TTree, a setting to increase the file size limit is also included by default.\n",
    "description": "",
    "tags": [
      "CRIB"
    ],
    "title": "User config",
    "uri": "/artemis_crib/crib_parts/userconfig/index.html"
  },
  {
    "breadcrumb": "Setting",
    "content": "last modified: 2023-11-14 by Kodai Okawa Before starting analysis, you need to build. The current version of the artemis use “cmake” so the following steps must be taken.\n\u003e artlogin (username) \u003e mkdir build \u0026\u0026 cd build \u003e cmake .. \u003e make -j4 \u003e make install \u003e acdacd is the alias command that is definded after artlogin command. (acd = cd your_work_directory) Also if you changed some processor, you need to do these process.\nThen some important configuration files are automatically created.\n\u003e tree -L 1 . +├── artemislogon.C +├── thisartemis-crib.sh -- snip -- └── run_artemis.cpp Before starting artemis, you need to load the thisartemis-crib.sh. The artlogin command is also used to read this script, so run this command again after the build.\n\u003e artlogin (usename) \u003e aThen you can start artemis by using a command!\n",
    "description": "",
    "tags": [
      "CRIB"
    ],
    "title": "Build",
    "uri": "/artemis_crib/setting/build/index.html"
  },
  {
    "breadcrumb": "Installation",
    "content": "last modified: 2023-11-02 by Kodai Okawa Artemis uses ROOT library.\nWe confirmed that version 6.28 of the ROOT will work well, but if the ROOT updates, we are not sure that the ARTEMIS will work well, so we recommend to build from the sources.\nFor detailded information, please refer Installing ROOT Recommendations are described below.\n# The latest stable branch gets updated automatically on each release. # You may update your local copy by issuing a `git pull` command from within `root_src/`. cd hoge git clone --branch latest-stable --depth=1 https://github.com/root-project/root.git root_src mkdir root_build root_install \u0026\u0026 cd root_build cmake -DCMAKE_INSTALL_PREFIX=../root_install ../root_src # \u0026\u0026 check cmake configuration output for warnings or errors cmake --build . -- install -j4 # if you have 4 cores available for compilation source ../root_install/bin/thisroot.sh # or thisroot.{fish,csh}If there are any problems at the compile, additional packages may need to be installed. See also dependencies.\nInfo If errors related to xrootd, TBB and clad occur, the cmake options -Dxrootd=OFF, -Dimt=OFF and -Dclad=OFF may work respectively.\nI recommend to write source thisroot.sh part in the .bashrc/.zshrc to load this library.\n",
    "description": "",
    "tags": null,
    "title": "ROOT",
    "uri": "/artemis_crib/installation/root/index.html"
  },
  {
    "breadcrumb": "",
    "content": "Artemis configuration varies from experiment to experiment. We would like to explain in this chapter how they are configured and used in CRIB experiment.\nAnalysis environment Online-mode analysis User config New commands Minor changes ",
    "description": "",
    "tags": null,
    "title": "CRIB Configuration",
    "uri": "/artemis_crib/crib_parts/index.html"
  },
  {
    "breadcrumb": "Example \u003e Online analysis",
    "content": "last modified: 2023-12-20 by Kodai Okawa ",
    "description": "",
    "tags": [],
    "title": "PPAC",
    "uri": "/artemis_crib/example/online_analysis/ppac/index.html"
  },
  {
    "breadcrumb": "Example \u003e Preparation",
    "content": "last modified: 2023-12-15 by Kodai Okawa ",
    "description": "",
    "tags": [],
    "title": "MWDC calibration",
    "uri": "/artemis_crib/example/preparation/mwdc_calibration/index.html"
  },
  {
    "breadcrumb": "CRIB Configuration",
    "content": "last modified: 2024-01-20 by Kodai Okawa Various commands (mainly the same with ANAPAW commands) have been developed for CRIB experiment. For more information, please click here (src-crib/commands). These commands are registered in userlogon.C. (See previous section.)\nThis section explains how to use them.\nstart stop xfitg xblow xyblow xstatus tcutg erase draw the default figures: start This is exactly the same as the resume command, because ANAPAW starts the event loop with start instead of resume.\nstop This is exactly the same as the suspend command, because ANAPAW stops the event loop with stop instead of suspend.\nxfitg For 1D histograms, by selecting the two ends of two points, the peak between them is fitted with a Gaussian.\nartemis [7] xf Info in \u003cart::TCmdXfitg::Cmd\u003e: click on the lowest edge: Info in \u003cart::TCmdXfitg::Cmd\u003e: click on the highest edge: Info in \u003cart::TCmdXfitg::Cmd\u003e: X1: -1437.56, X2: -1419.11 FCN=81.6642 FROM MIGRAD STATUS=CONVERGED 71 CALLS 72 TOTAL EDM=3.35095e-09 STRATEGY= 1 ERROR MATRIX ACCURATE EXT PARAMETER STEP FIRST NO. NAME VALUE ERROR SIZE DERIVATIVE 1 Constant 1.16439e+03 2.43862e+01 8.08454e-02 9.04256e-07 2 Mean -1.43081e+03 4.54001e-02 6.82262e-04 -1.74034e-03 3 Sigma 2.81435e+00 4.07888e-02 1.55351e-05 -3.15946e-03 artemis [8] xblow For 1D histograms, select both ends and crop the histogram between them.\nartemis [10] xblo Info in \u003cart::TCmdXblow::Run\u003e: click on the lowest edge: Info in \u003cart::TCmdXblow::Run\u003e: click on the highest edge: Info in \u003cart::TCmdXblow::Run\u003e: X1: -1439.3, X2: -1417.37 Info in \u003cart::TCmdXblow::Run\u003e: id = 2 hist is created artemis [11] xyblow For 2D histograms, select both corners and crop the histogram between them.\nartemis [60] xyblo Info in \u003cart::TCmdXYblow::Run\u003e: click on one corner: Info in \u003cart::TCmdXYblow::Run\u003e: X1: 9.2154, Y1: 46.6159 Info in \u003cart::TCmdXYblow::Run\u003e: click on the other corner: Info in \u003cart::TCmdXYblow::Run\u003e: X2: 21.7032, Y2: 23.952 Info in \u003cart::TCmdXYblow::Run\u003e: id = 6 hist is created artemis [61] xstatus For 2D histograms, select both corners and determine the ratio of the total number of events.\nartemis [8] xs Info in \u003cart::TCmdXstatus::Cmd\u003e: click on one corner: Info in \u003cart::TCmdXstatus::Cmd\u003e: X1: 14.1496, Y1: 41.4826 Info in \u003cart::TCmdXstatus::Cmd\u003e: click on the other corner: Info in \u003cart::TCmdXstatus::Cmd\u003e: X2: 21.0941, Y2: 31.9909 ------------------ selected = 976, total = 7526 ratio = 0.129684 (12.9684%) artemis [9] tcutg For 2D histograms, this command create TCutG object and store in a ROOT file. If you select to save the object, the file will place to the gate/*.root directory. There objects are automatically loaded. (please check user config page.)\nThis is the example how to use this command.\nartemis [] ht something artemis [] tc Info in \u003cTCatCmdTCutG::Cmd\u003e: Xaxis name : f2ppac.fX Yaxis name : f2ppac.fY Info in \u003cTCatCmdTCutG::Cmd\u003e: When you have finished specifying the area (last point), double-click on it. Info in \u003cTCatCmdTCutG::Cmd\u003e: (x, y) = (9.050404, 10.301410) Info in \u003cTCatCmdTCutG::Cmd\u003e: (x, y) = (5.047341, -8.294592) Info in \u003cTCatCmdTCutG::Cmd\u003e: (x, y) = (-12.183236, -3.839300) Info in \u003cTCatCmdTCutG::Cmd\u003e: (x, y) = (3.306878, -15.074384) Info in \u003cTCatCmdTCutG::Cmd\u003e: (x, y) = (-3.306878, -32.120720) Info in \u003cTCatCmdTCutG::Cmd\u003e: (x, y) = (9.920635, -15.461801) Info in \u003cTCatCmdTCutG::Cmd\u003e: (x, y) = (18.274854, -29.989928) Info in \u003cTCatCmdTCutG::Cmd\u003e: (x, y) = (16.186299, -11.200217) Info in \u003cTCatCmdTCutG::Cmd\u003e: (x, y) = (35.157338, -4.420425) Info in \u003cTCatCmdTCutG::Cmd\u003e: (x, y) = (14.271791, -4.807841) Info in \u003cTCatCmdTCutG::Cmd\u003e: (x, y) = (10.964912, 9.332869) Info in \u003cTCatCmdTCutG::Cmd\u003e: (x, y) = (10.964912, 9.332869) if you want to save it, input the TCutG name [name/exit] f2star Info in \u003cTCatCmdTCutG::Cmd\u003e: Created gate/f2star.root To select an area, click on the vertices of the area you want to select, then double-click at the last vertex. If you want to save this object, enter the “cut” name. In this example, I input the f2star as the object name. If you don’t want to save, enter “exit”.\nThen the gate/f2star.root will be created. And after reload the artemis, the gate will be loaded automatically and we can use histogram definition and “tree-\u003eDraw” selection part. For the detail please check gate page.\nartemis [] tree-\u003eDraw(\"f2ppac.fY:f2ppac.fX\u003e\u003e(200,-50.,50., 200,-50.,50.)\",\"f2star\",\"colz\") —under development— erase draw ",
    "description": "",
    "tags": [
      "CRIB"
    ],
    "title": "New commands",
    "uri": "/artemis_crib/crib_parts/newcommand/index.html"
  },
  {
    "breadcrumb": "Setting",
    "content": "last modified: 2023-11-14 by Kodai Okawa Before configuring the settings according to your experiment, let’s check that artemis is working!\n\u003e artlogin (username) \u003e a # start the artemis!Then the prompt change to the artemis [0]. This means you are in artemis console!\nAnalysis using artemis use event loop. It is therefore necessary to load a file that specifies what kind of analysis is to be performed. This file is called the steering file. As an example, let’s check the operation using a steering file that only generates random numbers!\nThe command to load the steering file is add.\nartemis [0] add steering/example/example.tmpl.yaml NUM=0001 MAX=10This means that 10000 random numbers from 0 to MAX=10 are generated (10000 event loops). NUM=0001 is the ID, so any number is okay (related to outputed file name).\nAnd the command to start the event loop is resume. (Often abbreviated as “resume” or “re”. The abbreviated form will also run without problems if there are no conflicts with other commands.)\nartemis [1] res artemis [2] Info in \u003cart::TTimerProcessor::PostLoop\u003e: real = 0.02, cpu = 0.02 sec, total 10000 events, rate 500000.00 evts/secWhen the time taken for such an analysis is displayed, it means that all event loops have been completed. If you are doing a time-consuming analysis and want to suspend the event loop in the middle, suspend command is used. (Often “sus” or “su” is used.)\nartemis [2] susThis event loop creates histogram objects (inherit from TH1 or TH2) and a TTree object. Let’s look at how to access each of these.\nHistogram Details are given in the Histograms section, but histograms are created in an internal directory. To access it, you need to use the same commands as for the linux command, such as “ls” or “cd”, to get to that directory.\nartemis [2] ls artemis \u003e 0 art::TTreeProjGroup test2 test (2) # the first \"\u003e\" means your current position 1 art::TTreeProjGroup test test 2 art::TAnalysisInfo analysisInfo # then let's move to the \"test\" directory! artemis [3] cd 1 artemis [4] ls test \u003e 0 art::TH1FTreeProj hRndm random valueYou can use the command ht [ID] to display a histogram. The ID can be omitted if it is already represented by \u003e.\nartemis [5] zone # make artemis canvas artemis [6] ht 0 Next, let’s also check the histogram in “test2” directory and display two histograms vertically at the same time!\nartemis [7] zone 2 1 # row=2, column=1 artemis [8] ht 0 # show the current hist artemis [9] cd .. artemis [10] ls artemis \u003e 0 art::TTreeProjGroup test2 test (2) 1 art::TTreeProjGroup test test 2 art::TAnalysisInfo analysisInfo artemis [11] cd 0 test2 \u003e 0 art::TH1FTreeProj hRndm2 random number artemis [12] ht 0 TTree Now consider displaying a diagram from a TTree object. The file is created at here.\nartemis [13] fls files 0 TFile output/0001/example_0001.tree.root (CREATE)We use the fcd command to navigate to this root file.\nartemis [14] fcd 0 artemis [15] ls output/0001/example_0001.tree.root \u003e 0 art::TAnalysisInfo analysisInfo 1 art::TArtTree tree treeThe command branchinfo (“br”) displays a list of the branches stored in this tree.\nartemis [16] br random art::TSimpleDataAt the same time, the ROOT command can be used.\nartemis [17] tree-\u003ePrint() ****************************************************************************** *Tree :tree : tree * *Entries : 10000 : Total = 600989 bytes File Size = 86144 * * : : Tree compression factor = 7.00 * ****************************************************************************** *Br 0 :random : art::TSimpleData * *Entries : 10000 : Total Size= 600582 bytes File Size = 85732 * *Baskets : 1 : Basket Size= 3200000 bytes Compression= 7.00 * *............................................................................* Info What is stored in the branch is not the usual type like “double” or “int”, but a class defined in artemis. Therefore, the “artemis” root file cannot be opened by usual ROOT.\nAccessing data in a branch’s data class requires the use of public variables and methods, which can be examined by providing arguments to branchinfo [branch name] or classinfo [class name].\nartemis [18] br random art::TSimpleData Data Members Methods Bool_t CheckTObjectHashConsistency TSimpleData\u0026 operator= TSimpleData\u0026 operator= See also art::TSimpleDataBase\u003cdouble\u003e artemis [19] cl art::TSimpleDataBase\u003cdouble\u003e art::TSimpleDataBase\u003cdouble\u003e Data Members double fValue Methods void SetValue double GetValue Bool_t CheckTObjectHashConsistency TSimpleDataBase\u003cdouble\u003e\u0026 operator= See also art::TDataObject base class for data objectTherefore, it can be seen that it can be accessed by the value fValue.\nartemis [20] zone artemis [21] tree-\u003eDraw(\"random.fValue\u003e\u003e(100,0.,10.)\")Other useful commands artemis [*] help # show the commands we can use artemis [*] save # save the current canvas artemis [*] print # print the current canvas (send to the printer, need to configure) artemis [*] unzoom artemis [*] lgy, lgz, lny, lnz # linear or log scale",
    "description": "",
    "tags": [],
    "title": "artemis commands",
    "uri": "/artemis_crib/setting/artemis_commands/index.html"
  },
  {
    "breadcrumb": "Installation",
    "content": "last modified: 2023-11-02 by Kodai Okawa Info The yaml-cpp can be installed by some package manager like apt or dnf, but I’m not sure it will work or not in the installation of the artemis.\nCurrent version of the artemis use yaml-cpp-0.7 or higher. In order to use this library, please install from the repository.\nSee also Github repo and README of the artemis Please install it as a shared object like below commands.\ncd hoge git clone https://github.com/jbeder/yaml-cpp.git cd yaml-cpp mkdir build \u0026\u0026 cd build cmake -DYAML_BUILD_SHARED_LIBS=ON -DBUILD_TESTING=OFF .. make sudo make installDefault install path is /usr/local/lib or /usr/local/lib64. If you do not want to pollute the general environment, specify CMAKE_INSTALL_PREFIX and set PATH environment variable.\ncmake -DCMAKE_INSTALL_PREFIX=/foo/bar -DYAML_BUILD_SHARED_LIBS=ON -DBUILD_TESTING=OFF ..",
    "description": "",
    "tags": null,
    "title": "yaml-cpp",
    "uri": "/artemis_crib/installation/yaml-cpp/index.html"
  },
  {
    "breadcrumb": "",
    "content": "Up to now, we have introduced the installation and concepts of artemis. This chapter will show you how to analyse with artemis through practical examples; if you want to know how to use artemis, it is no problem to start reading from here.\nPreparation Basic Tref for V1190 PPAC calibration MWDC calibration Alpha calibration MUX calibration Set parameters Git Online analysis F1 Beam PID F2 PPAC MWDC SSD F3 Gate Shifter task Scaler Timestamp Check raw data Offline analysis New processors Merge files Python environment pyROOT MC Simulation Beam_generator Nbodyreaction Geometry Detect_particle Solidangle ",
    "description": "",
    "tags": null,
    "title": "Example",
    "uri": "/artemis_crib/example/index.html"
  },
  {
    "breadcrumb": "Example \u003e Online analysis",
    "content": "last modified: 2023-12-20 by Kodai Okawa ",
    "description": "",
    "tags": [],
    "title": "MWDC",
    "uri": "/artemis_crib/example/online_analysis/mwdc/index.html"
  },
  {
    "breadcrumb": "Example \u003e Preparation",
    "content": "last modified: 2023-12-23 by Kodai Okawa This is the CRIB alpha source information. (unit: MeV)\nID alpha-2 alpha-3 4.780 3.148 5.480 5.462 5.795 5.771 calibration files SSD calibration files need to be set at prm/ssd/ directory. The directory structure is like this:\n$ tree -L 2 prm/ssd prm/ssd ├── ch2MeV.dat # test file ├── ch2ns.dat # test file ├── f2ch2MeV.dat ├── f2ch2MeV_raw.dat ├── f2ch2ns.dat ├── tel1 │ ├── ch2MeV_dEX.dat │ ├── ch2MeV_dEX_raw.dat │ ├── ch2MeV_dEY.dat │ ├── ch2MeV_dEY_raw.dat │ ├── ch2MeV_E.dat │ ├── ch2MeV_E_raw.dat │ ├── ch2ns_dEX.dat │ ├── ch2ns_dEY.dat │ ├── ch2ns_E.dat │ └── tel_conf.yaml # telescope configuration, explain later -- snip --The prm/ssd/ch2MeV.dat and prm/ssd/ch2ns.dat are used for test, so in the beam time measurement, actually this files are not necessory. And prm/ssd/f2* files are used for F2SSD calibration, and files in prm/ssd/tel1/ directory are used for SSDs of a telescope.\nThe ch2ns.dat depends on TDC setting, so basically we don’t have to care so muc (Usually the setting (the value) is same with previous experiment.), so we have to prepare the ch2MeV.dat files!\nNote The file name need to be set like this example. The loaded parameter file name is defined SSD steering file, and we don’t want to change the SSD steering files so much, so please use such file names.\nThe “ch2MeV.dat” file format is like this:\n​ prm/ssd/f2ch2MeV.dat prm/ssd/f2ch2MeV.dat # offset gain 1.7009 0.0173 0.0 1.0 # if there are some SSDs or strip SSD, you can add the line. $$ E~\\mathrm{[MeV]} = \\mathrm{offset} + \\mathrm{gain} \\times \\mathrm{ch} $$Usage We prepared useful macros to calibrate many SSDs. Please check these for more information.\nmacro/AlphaCalibration.C macro/run_AlphaCalibraion.C It is sufficient to use the AlphaCalibration.C, but it is recommended to use the run_AlphaCalibration.C to keep a record of what arguments were used to calibrate.\nAfter you prepared alpha calibration data and steering file (for example steering/calibration.yaml) to show raw data, you can use this macro.\n$ acd $ vi macro/run_AlphaCalibration.C # please set the parameters. # instraction is written in this file $ a artemis [0] add steering/hoge.yaml NAME=hoge NUM=0000 artemis [1] res artemis [2] .x macro/run_AlphaCalibration.CThen the parameter file that defined at the “run_AlphaCalibration.C” and calibration figures will be created automatically.\nThese are example of the figures;\nraw fitting figure (figure/calib/tel*/ch2MeV_*/raw/) calibration line and residual figure (figure/calib/tel*/ch2MeV_*/calibration/) $ a artemis [0] add steering/hoge.yaml NAME=hoge NUM=0000 artemis [1] res artemis [2] fcd 0 artemis [3] zo artemis [4] tree-\u003eDraw(\"...\") # draw calibrated data artemis [5] gStyle-\u003eSetOptStat(0) artemis [6] sa ",
    "description": "",
    "tags": [],
    "title": "Alpha calibration",
    "uri": "/artemis_crib/example/preparation/alpha_calibration/index.html"
  },
  {
    "breadcrumb": "Setting",
    "content": "last modified: 2023-11-14 by Kodai Okawa From this section, we start to configure the settings according to the actual experimental setup. The setting files are followings:\n\u003e tree . ├── mapper.conf ├── conf │ ├── map │ │ ├── ppac │ │ │ ├── dlppac.map -- snip -- │ └── seg │ ├── modulelist.yaml │ └── seglist.yaml -- snip --1. What is the map file? The data obtained from an ADC/TDC is in the form of, for example, “The data coming into channel 10 of an ADC with an ID of 1 is 100”.\n--- title: Data flow example --- graph LR; A{detector} --\u003e|signal| B(TDC/ADC\u003cbr\u003e\u003c/br\u003eID=1, ch=10) B --\u003e|value=100| C[\u003cstrong\u003eData build\u003c/strong\u003e\\nridf file] The role of the map file is to map this value of “100” to an ID that is easy to analyse. An ID that is easy to analyse means, for example, that even if signals from the same detector are acquired with different ADCs/TDCs, the same ID is easier to handle in the analysis.\n--- title: Data flow example --- graph LR; A(TDC/ADC\u003cbr\u003e\u003c/br\u003eID=1, ch=10) --\u003e|value=100| B[\u003cstrong\u003eData build\u003c/strong\u003e\\nridf file] B --\u003e|value=100 mapping to| C(analysis\u003cbr\u003e\u003c/br\u003eID=2, ch=20) After mapping, we can check the data of this “100” from ID=2 and ch=20. This ID and channel (2, 20) are provided for convenience, so you can freely set them.\nSo, in summary, the map file role is like this:\n--- title: role of the map file --- graph LR; A(DAQ ID\u003cbr\u003e\u003c/br\u003eID=1, ch=10) \u003c--\u003e|mapping| B(analysis ID\u003cbr\u003e\u003c/br\u003eID=2, ch=20) 2. map files CRIB is using Babirl for the DAQ system. In this system, the DAQ ID represented in the example is determined by five parameters.\ndevice ID (dev) focal plane (fp) detector ID (det) geometry ID (geo) channel (ch) The dev, fp, det and geo parameters can be set from DAQ setting. For the CRIB experiment, conventionally we set dev=12, fp=0–2 (for each MPV), det=6,7 (6=energy, 7=timing) and geo=from 0. But you can change it freely.\nAnd analysis ID represented in the example is determined by two parameters.\nCategory ID (CatID, cid) id (fID) Of cource you can also set the value freely.\nThe format of the map file is followings:\n# [category] [id] [[device] [focus] [detector] [geo] [ch]] .... 1, 0, 12, 1, 6, 0, 0 Note The id should start from “0”. The ADC/TDC channel start from “0”. The leading “#” is treated as a comment statement. you can set several “DAQ ID” to one “analysis ID” like this: # map for SSD # [category] [id] [[device] [focus] [detector] [geo] [ch]] .... # # Map: energy, timing # #-------------------------------------------------------------------- 1, 0, 12, 1, 6, 0, 0, 12, 2, 7, 0, 0 Please create map files for all detectors like this!\n3. mapper.conf You can select the map file to be loaded with this file. This is especially useful when separating map files for testing from map files for the experiment.\nThe format is followings: (path/to/the/map/file number)\n# file path for configuration, relative to the working directory # (path to the map file) (Number of columns) # cid = 1: rf conf/map/rf/rf.map 1In the note example above, the number is 2.\nPlease do not forget to add to the mapper.conf after you add some map files.\n4. (option) segment files This conf files are used when you use “chkseg.yaml” steering file. This steering file create raw data 2D histograms. I will describe in the Example: online_analysis/Check raw data in detail.\n",
    "description": "",
    "tags": [
      "CRIB"
    ],
    "title": "Map configuration",
    "uri": "/artemis_crib/setting/map_config/index.html"
  },
  {
    "breadcrumb": "Installation",
    "content": "last modified: 2023-11-02 by Kodai Okawa From the current situation, CRIB experiment doesn’t use GET system, so we describe how to install it without linking it to GET decoder.\nAlso, it can link to openMPI, but the below commands assume not using openMPI. See artemis repo for more information.\ncd hoge git clone https://github.com/artemis-dev/artemis.git -b develop cd artemis mkdir build cd build cmake -DCMAKE_INSTALL_PREFIX=../install .. make -j8 make install source ../install/bin/thisartemis.shThen, \u003cCMAKE_INSTALL_PREFIX\u003e/bin/thisartemis.sh will be created and this shell script can configure the environment (ROOT, yaml-cpp, artemis libraries) to use artemis.\nAlso, I recommend to write source thisartemis.sh part in the .bashrc/.zshrc to load this library.\nAnother option is to use module command to manage the environment. It is also written in artemis repo.\nNote This is 2023/10/29 current information\nOkawa think there is a grammatical error in the sources/main/thisartemis.sh.in, so I changed like:\n-if [ \"@BUILD_GET@\" == \"ON\" ]; then +if [[ \"@BUILD_GET@\" == \"ON\" ]]; then export LD_LIBRARY_PATH=@GET_LIB_DIR@:$LD_LIBRARY_PATH fi -if [ \"@MPI_CXX_FOUND@\" == \"TRUE\" ]; then +if [[ \"@MPI_CXX_FOUND@\" == \"TRUE\" ]]; then dir=@MPI_CXX_LIBRARIES@ libdir=\"$(dirname $dir)\" ",
    "description": "",
    "tags": [
      "CRIB"
    ],
    "title": "artemis",
    "uri": "/artemis_crib/installation/artemis/index.html"
  },
  {
    "breadcrumb": "",
    "content": "Cannot be analysed in online mode… When you start the event loop in online mode and artemis gets stuck, babian may not have been activated. There is a shellscript to run the “babian” in cribana PC.\n~/bin/run_babian ps aux | grep babi # check if the \"babian\" process is working or not “chkridf” command shows “Rev”, “Dev”, “FP”, “Det” and “Mod” ID, but they are different from map file configuration…? chkridf command shows like this:\nchkridf hoge.ridf-- snip -- : Segment Header / blkn=1 hd1 = 0x2100004c ly=2, cid=4, size=76, efn=120 Segment ID = 12600853 (0x00c04615) Rev 0 / Dev 12 / FP 1 / Det 6 / Mod 21 2000 0200 4072 0000 406c 0010 405f 0001 4068 0011 406a 0002 4053 0012 4058 0003 4058 0013 4051 0004 4066 0014 404d 0005 4047 0015 4045 0006 4056 0016 405a 0007 404b 0017 4050 0008 406c 0018 404b 0009 4069 0019 4059 000a 4051 001a 404e 000b 405f 001b 4064 000c 4052 001c 4033 000d 4055 001d 4064 000e 4067 001e 4043 000f 4052 001f 1dd2 0401 1dd2 0601 -- snip -- ",
    "description": "",
    "tags": null,
    "title": "Q\u0026A",
    "uri": "/artemis_crib/q_and_a/index.html"
  },
  {
    "breadcrumb": "Example \u003e Online analysis",
    "content": "last modified: 2023-12-20 by Kodai Okawa ",
    "description": "",
    "tags": [],
    "title": "SSD",
    "uri": "/artemis_crib/example/online_analysis/ssd/index.html"
  },
  {
    "breadcrumb": "Setting",
    "content": "last modified: 2023-11-14 by Kodai Okawa The steering file (yaml format) is a file that directs the process of how the obtained data is to be processed. The artemis is an object-oriented program whose components are called processors, which are combined to process data.\nThe main role of the “processor” is to process data from an input data called InputCollection and create an output data called OutputCollection. This “OutputCollection” will be stored into the root file as a “tree”. Complex processing can be performed by using “processor” in multiple steps.\nI will explain how to create this “steering” file using Si detector data as an example.\n--- title: example of the data process structure --- graph TD; subgraph event loop A--\u003eB(mapping processor\u003cbr\u003e\u003c/br\u003eInputCollection: decoded data\\nOutputCollection: Si raw data) B--\u003eC(calibration processor\u003cbr\u003e\u003c/br\u003eInputCollection: Si raw data\\nOutputCollection: Si calibrated data) C--\u003eX((event end)) X--\u003eA end subgraph DAQ D(Raw binary data)--\u003eA(decode processor\u003cbr\u003e\u003c/br\u003eInputCollection: raw data\\nOutputCollection: decoded data) end Steering file: Silicon data case First, I describe what is the Anchor and how to use command line arguments. See example here.\n​ chkssd.yaml chkssd.yaml Anchor: - \u0026input ridf/@NAME@@NUM@.ridf - \u0026output output/@NAME@/@NUM@/chkssd@NAME@@NUM@.root - \u0026histout output/@NAME@/@NUM@/chkssd@NAME@@NUM@.hist.root You can use variables from elsewhere in the steering file by declaring them as such. For example if you write:\nsomething: *inputThis unfolds as follows:\nsomething: ridf/@NAME@@NUM@.ridfVariables enclosed in @ can also be specified by command line arguments. For example, If you command like the following in the artemis console,\nartemis [1] add steering/chkssd.yaml NAME=run NUM=0000it is considered as\n​ chkssd.yaml chkssd.yaml Anchor: - \u0026input ridf/run0000.ridf - \u0026output output/run/0000/chkssdrun0000.root - \u0026histout output/run/0000/chkssdrun0000.hist.root 1. General processor When using the “Babirl”, the data file will be in the form of “ridf”. In this case, the beginning and end of the steering file is usually as follows.\n​ chkssd.yaml chkssd.yaml Processor: - name: timer type: art::TTimerProcessor - name: ridf type: art::TRIDFEventStore parameter: OutputTransparency: 1 InputFiles: - *input SHMID: 0 - name: mapper type: art::TMappingProcessor parameter: OutputTransparency: 1 # -- snip -- - name: outputtree type: art::TOutputTreeProcessor parameter: FileName: - *output TTimerProcessor: measure the time taken to process data TRIDFEventStore: decode the ridf file and store the value in EventStore (see below) TMappingProcessor: read mapper.conf for mapping TOutputTreeProcessor: writes data to the root file OutputTransparency is set to 1, indicating that “OutputCollection” is not exported to the root file.\n2. Mapping processor The “mapping processor” puts the data stored in the “EventStore” into a certain data class based on “mapper.conf”. Assume the following map file is used.\n# map for SSD # [category] [id] [[device] [focus] [detector] [geo] [ch]] .... # # Map: energy, timing # #-------------------------------------------------------------------- 1, 0, 12, 1, 6, 0, 0, 12, 2, 7, 0, 0In this case, since we are assuming data from the Si detector, let’s consider putting it in a data class that stores energy and timing data, “TTimingChargeData”! The processor mapping to this data class is “TTimingChargeMappingProcessor”.\n​ chkssd.yaml chkssd.yaml Processor: - name: proc_ssd_raw type: art::TTimingChargeMappingProcessor parameter: CatID: 1 ChargeType: 1 ChargeTypeID: 0 TimingTypeID: 1 Sparse: 1 OutputCollection: ssd_raw CatID: enter here the same number as the cid (category ID) in the map file. ChargeType: there are various ways to store energy (charge) and timing using this processor, but this time “1” is specified to use the processing method using ADC and TDC. Charge/TimingTypeID: The map file has two sets of five parameters that specify the DAQ ID. Which of these parameters specifies which represents the energy (charge) and timing. (it start from “0”) Sparse: parameter for the output data structure OutputCollection: name of the data class to be output Then, you can access the ssd_raw data by using like tree-\u003eDraw(\"ssd_raw.fCharge\")\n3. Calibration processor While the data in the “ssd_raw” are raw channel of the ADC and TDC, it is important to see the data calibrated to energy and time. I will explain the details in Example: preparation/macro, but here I will discuss the calibration processors assuming that the following appropriate calibration files have been created.\nprm/ssd/ch2MeV.dat prm/ssd/ch2ns.dat Now, let’s load these files.\n​ chkssd.yaml chkssd.yaml Processor: - name: proc_ssd_ch2MeV type: art::TParameterArrayLoader parameter: Name: prm_ssd_ch2MeV Type: art::TAffineConverter FileName: prm/ssd/ch2MeV.dat OutputTransparency: 1 - name: proc_ssd_ch2ns type: art::TParameterArrayLoader parameter: Name: prm_ssd_ch2ns Type: art::TAffineConverter FileName: prm/ssd/ch2ns.dat OutputTransparency: 1 To calibrate data contained in a TTimingChargeData class, a TTimingChargeCalibrationProcessor processor is used.\n​ chkssd.yaml chkssd.yaml Processor: - name: proc_ssd type: art::TTimingChargeCalibrationProcessor parameter: InputCollection: ssd_raw OutputCollection: ssd_cal ChargeConverterArray: prm_ssd_ch2MeV TimingConverterArray: prm_ssd_ch2ns Note here that “InputCollection”, “ChargeConverterArray”, and “TimingConverterArray” use the same names as the highlighted lines in the code block above.\nInfo The arguments to be used will vary depending on the processor used, so please check and write them according to the situation. If you want to check from artemis console, you can use “processordescription” command like this\n\u003e artlogin (username) \u003e a artemis [0] processordescription art::TTimingChargeCalibrationProcessor Processor: - name: MyTTimingChargeCalibrationProcessor type: art::TTimingChargeCalibrationProcessor parameter: ChargeConverterArray: no_conversion # [TString] normally output of TAffineConverterArrayGenerator InputCollection: plastic_raw # [TString] array of objects inheriting from art::ITiming and/or art::ICharge InputIsDigital: 1 # [Bool_t] whether input is digital or not OutputCollection: plastic # [TString] output class will be the same as input OutputTransparency: 0 # [Bool_t] Output is persistent if false (default) TimingConverterArray: no_conversion # [TString] normally output of TAffineConverterArrayGenerator Verbose: 1 # [Int_t] verbose level (default 1 : non quiet) 4. Split files If you want to analyse a large number of detectors, not just Si detectors, writing everything in one steering file will result in a large amount of content that is difficult to read.\nIn that case, we can use “include” node!\nIn the examples we have written so far, let’s only use a separate file for the part related to the analysis of the Si detector.\n​ chkssd.yaml chkssd.yaml # -- snip -- Processor: # -- snip -- - include: ssd/ssd_single.yaml # -- snip -- ​ ssd/ssd_single.yaml ssd/ssd_single.yaml Processor: # parameter files - name: proc_ssd_ch2MeV type: art::TParameterArrayLoader parameter: Name: prm_ssd_ch2MeV Type: art::TAffineConverter FileName: prm/ssd/ch2MeV.dat OutputTransparency: 1 - name: proc_ssd_ch2ns type: art::TParameterArrayLoader parameter: Name: prm_ssd_ch2ns Type: art::TAffineConverter FileName: prm/ssd/ch2ns.dat OutputTransparency: 1 # data process - name: proc_ssd_raw type: art::TTimingChargeMappingProcessor parameter: CatID: 1 ChargeType: 1 ChargeTypeID: 0 TimingTypeID: 1 Sparse: 1 OutputCollection: ssd_raw - name: proc_ssd type: art::TTimingChargeCalibrationProcessor parameter: InputCollection: ssd_raw OutputCollection: ssd_cal ChargeConverterArray: prm_ssd_ch2MeV TimingConverterArray: prm_ssd_ch2ns In this way, the contents of “chkssd.yaml” can be kept concise, while the same process is carried out. Note that the file paths here are relative to the paths from the steering directory. Parameter files, for example, are relative paths from the working directory (one level down).\nUtilising file splitting also makes it easier to check the steering files that analyse a large number of detectors like this.\n​ chkall.yaml chkall.yaml # -- snip -- Processor: # -- snip -- - include: rf/rf.yaml - include: ppac/f1ppac.yaml - include: ppac/dlppac.yaml - include: mwdc/mwdc.yaml - include: ssd/ssd_all.yaml # -- snip -- Info When you include other files, you can set arguments. This can be used, for example, to share variables. Details will be introduced in the example section.\nSummary The whole steering file is as follows:\n​ chkssd.yaml chkssd.yaml Anchor: - \u0026input ridf/@NAME@@NUM@.ridf - \u0026output output/@NAME@/@NUM@/chkssd@NAME@@NUM@.root - \u0026histout output/@NAME@/@NUM@/chkssd@NAME@@NUM@.hist.root Processor: - name: timer type: art::TTimerProcessor - name: ridf type: art::TRIDFEventStore parameter: OutputTransparency: 1 InputFiles: - *input SHMID: 0 - name: mapper type: art::TMappingProcessor parameter: OutputTransparency: 1 - include: ssd/ssd_single.yaml # output root file - name: outputtree type: art::TOutputTreeProcessor parameter: FileName: - *output ​ ssd/ssd_single.yaml ssd/ssd_single.yaml Processor: # parameter files - name: proc_ssd_ch2MeV type: art::TParameterArrayLoader parameter: Name: prm_ssd_ch2MeV Type: art::TAffineConverter FileName: prm/ssd/ch2MeV.dat OutputTransparency: 1 - name: proc_ssd_ch2ns type: art::TParameterArrayLoader parameter: Name: prm_ssd_ch2ns Type: art::TAffineConverter FileName: prm/ssd/ch2ns.dat OutputTransparency: 1 # data process - name: proc_ssd_raw type: art::TTimingChargeMappingProcessor parameter: CatID: 1 ChargeType: 1 ChargeTypeID: 0 TimingTypeID: 1 Sparse: 1 OutputCollection: ssd_raw - name: proc_ssd type: art::TTimingChargeCalibrationProcessor parameter: InputCollection: ssd_raw OutputCollection: ssd_cal ChargeConverterArray: prm_ssd_ch2MeV TimingConverterArray: prm_ssd_ch2ns \u003e acd \u003e a artemis [0] add steering/chkssd.yaml NAME=run NUM=0000",
    "description": "",
    "tags": [],
    "title": "Steering",
    "uri": "/artemis_crib/setting/steering/index.html"
  },
  {
    "breadcrumb": "Installation",
    "content": "last modified: 2023-11-02 by Kodai Okawa For the convinience, we use one directory to store raw data (ridf files) and make symbolic link to each user work directory. So first, we need to make raw data directory.\nThere are three option to do so.\nuse the default SSD/HDD of analysis PC use the external SSD/HDD of analysis PC (need to mount it) use network file system (NFS) and mount it 1 and 2 options are mainly used for offline analysis, while 3 option is used for online analysis.\n1. use the default SSD/HDD of analysis PC If you have large size of main storage, the one option is easiest way. Just like:\ncd ~ mkdir data (or where you want to put) cd data rsync hoge (cp or scp to put the raw data)The symbolic link process will be done in the next process.\n2. use the external SSD/HDD of analysis PC (need to mount it) When your main storage is not so large, you may think to use external storage. For example, main storage is used for OS installation and external storage is used for experimental data. (I think this case is for personal analysis using your own PC.)\nIn that case, you need to do:\nmount the external storage check and set the file permission to be able to read or write it. The format and mount process is very depend on the situation, so please check the way in other place. One important point is that we have output root file when we start to analysis, so it may need to make the directory for outputed root files in the external storage.\n3. use network file system (NFS) and mount it For online analysis, the best option is to get the data via a file server, as there is no time to transfer the raw data files each time.\nThis is example of CRIB system.\n--- title: Network system of CRIB --- graph LR; A(MPV E7) --\u003e D{\u003cstrong\u003eDAQ main PC\u003c/strong\u003e\u003cbr\u003e\u003c/br\u003efile server} B(MPV1 J1) --\u003e D C(MPV2 J1) --\u003e D D --\u003e E[Analysis PC] As this figure, we use file server in the DAQ main PC.\n3.1 server setting The OS of the DAQ PC is CentOS7, but I think it can be applied for current OS. (like yum -\u003e dnf) First, please install required package.\nsudo yum install -y rpcbind nfs-utilsThen prepare the raw data file directory for sharing.\nmkdir /data (any location) And setting file for nfs is /etc/exports, and here is the example.\n/data 192.168.1.5 /data 192.168.2.0/24(rw)The first one means the host of 192.168.1.5 can access the shared directory “/data”. In the default setting, users cannot write to this directory.\nThe host of the second line means the range that can access. If we add rw option, users can write to this directory. For the other options, please check the official site.\nFinally, the following command is used to reflect the settings.\nfirewall-cmd --permanent --zone=public --add-service=nfs firewall-cmd --reload systemctl start rpcbind systemctl enable rpcbind systemctl start nfs systemctl enable nfsIf you do not have a firewall set up, you do not need the relevant commands.\n3.2 client setting The package is also needed for client PC.\nsudo yum install -y nfs-utilsPrepare the mounted directory and mount it.\nmkdir /mnt/data sudo mount -t nfs host_IP_address:/data /mnt/data df -hIf you see the mounted configuration, your nfs configuration is complete.\nTo reflect the mount settings when the system is rebooted, add a setting to /etc/fstab.\n​ /etc/fstab /etc/fstab + host_IP_address:/data /mnt/data nfs defaults 0 0 sudo mount -a",
    "description": "",
    "tags": [
      "CRIB"
    ],
    "title": "mount setting",
    "uri": "/artemis_crib/installation/mount/index.html"
  },
  {
    "breadcrumb": "Example \u003e Online analysis",
    "content": "last modified: 2023-12-20 by Kodai Okawa ",
    "description": "",
    "tags": [],
    "title": "F3",
    "uri": "/artemis_crib/example/online_analysis/f3/index.html"
  },
  {
    "breadcrumb": "Example \u003e Preparation",
    "content": "last modified: 2023-12-15 by Kodai Okawa ",
    "description": "",
    "tags": [],
    "title": "MUX calibration",
    "uri": "/artemis_crib/example/preparation/mux_calibration/index.html"
  },
  {
    "breadcrumb": "Setting",
    "content": "last modified: 2023-11-14 by Kodai Okawa In the online analysis, it is important to have immediate access to data. The artemis can produce TTree object but long commands are needed to access, for example,\nartemis [1] fcd 0 # move to the created rootfile artemis [2] zone 2 2 # make a \"artemis\" 2x2 canvas artemis [3] tree-\u003eDraw(\"ssd_cal.fCharge:ssd_cal.fTiming\u003e(100,0.,100., 100,0.,100)\",\"ssd_cal.fCharge \u003e 1.0\",\"colz\")This would take time if there are some histograms that you want to display immediately…\nTherefore, if you know in advance the diagram you want to see, it is useful to predefine its histogram! The processor used is TTreeProjectionProcessor. I would like to explain how to use this one.\n1. Steering file Let’s look at how histograms are defined when looking at SSD data. First, let’s prepare the steering file as follows! please see previous section for omissions.\n​ chkssd.yaml chkssd.yaml # -- snip -- - include: ssd/ssd_single.yaml # Histogram - name: projection_ssd type: art::TTreeProjectionProcessor parameter: FileName: hist/ssd/ssd.yaml Type: art::TTreeProjection OutputFilename: *histout # output root file - name: outputtree type: art::TOutputTreeProcessor parameter: FileName: - *output The histogram is created based on the TTree object, so describe the processing of the histogram after the part that represents the data processing and before the part that outputs the TTree (TOutputTreeProcessor).\nThere are three points to note here.\nIt is possible to create a root file containing only a histogram as well as a root file containing a TTree. (Look at the node part of the OutputFilename.) The histogram itself is defined in a separate file to this one, written on the highlighted line above. The file paths are relative to the working directory. Therefore, I would now like to show the histogram definition file.\n2. Histogram file First please look at this example.\n​ hist/ssd/ssd.yaml hist/ssd/ssd.yaml 1anchor: 2 - \u0026energy [\"ssd_cal.fCharge\",100,0.,100.] 3 - \u0026timing [\"ssd_cal.fTiming\",100,0.,100.] 4alias: 5 energy_cut: ssd_cal.fCharge\u003e1.0; 6group: 7 - name: ssd_test 8 title: ssd_test 9 contents: 10 - name: ssd_energy 11 title: ssd_energy 12 x: *energy 13 14 - name: ssd_timing 15 title: ssd_timing 16 x: *timing 17 18 - name: ssd_energy and timing 19 title: ssd_energy and timing 20 x: *timing 21 y: *energy 22 cut: energy_cut This definition file consists of three parts.\n2.1 anchor The actual core part is the “2.3 group”, but “2.1 anchor” and “2.2 alias” are often used to make this part easier to write. The anchor defines the first argument of tree-\u003eDraw(\"ssd_cal.fCharge\u003e(100,0.,100.)\",\"ssd_cal.fCharge \u003e 1.0\")\nThe array stored in the variable named “energy” in the second line looks like [str, int, float, float] and has the following meanings\nstr: Name of the object (need double quote “”) int: Number of bins of histogram float: Minimum value of histogram range float: Maximum value of histogram range As you might imagine, inside the first argument you can also add operations such as TMath::Sqrt(ssd_cal.fCharge) or ssd_cal.fCharge-ssd_cal.fTiming, because it is the same with “tree-\u003eDraw”.\nNote, however, that the definition here is for one-dimensional histograms. Two-dimensional histograms will be presented in Section 2.3. It is very simple to write!\n2.2 alias This part is used when applying gates to events (often we call it as “cut” or “selection”). For example, if you only want to see events with energies above 1.0 MeV, you would write something like tree-\u003eDraw(\"energy\",\"energy\u003e1.0\").\nThe alias node is used to define the part of energy\u003e1.0\nNote A semicolon “;” at the end of the sentence may be needed…? please check the source.\n2.3 group The histogram is defined here and the object is stored in a directory in artemis (ROOT, TDirectory). In the example shown above, the directory structure would look like this:\n(It is not actually displayed in this way).\n# in artemis . └── ssd_test ├── ssd_energy (1D hist) ├── ssd_timing (1D hist) └── ssd_energy and timing (2D hist)The first “name” and “title” nodes are arguments of TDirectory instance. Also the second “name” and “title” nodes are arguments of instance of TH1 or TH2 object. The other “x”, “y” and “cut” is the important node!\nIf there are only “x” nodes -\u003e 1D histogram If there are both “x” and “y” nodes -\u003e 2D histogram In any case, it can be gated by adding a “cut” node. 3. Commands for histograms There are many useful command for checking the histogram objects. These are similar to the ANAPAW commands.\nls : check the artemis directory \u003e artlogin (username) \u003e a artemis [0] add steering/chkssd.yaml NAME=hoge NUM=0000 artemis [1] res artemis [2] sus artemis [3] ls # check the artemis directory artemis \u003e 0 art::TTreeProjGroup ssd_test ssd_test 1 art::TAnalysisInfo analysisInfo cd [ID] : move to the directory of the ID artemis [4] cd 0 artemis [5] ls ssd_test \u003e 0 art::TH1FTreeProj ssd_energy ssd_energy 1 art::TH1FTreeProj ssd_timing ssd_timing 2 art::TH2FTreeProj ssd_energy and timing ssd_energy and timing ht [ID] [option] : draw the histogram of the ID artemis [6] ht 0 artemis [7] ht 2 colz hn : draw the next ID histogram hb : draw the prev ID histogram 4. Template hist file When setting up several detectors of the same type and wanting to set up a histogram with the same content, it is tedious to create several files with only the names of the objects changed. In such cases, it is useful to allow the histogram definition file to have arguments.\nPlease look here first.\n​ chkssd.yaml chkssd.yaml # -- snip -- - include: ssd/ssd_single.yaml # Histogram - name: projection_ssd type: art::TTreeProjectionProcessor parameter: FileName: hist/ssd/ssd.yaml Type: art::TTreeProjection OutputFilename: *histout Replace: | name: ssd_cal # -- snip -- We add the highlighted lines. Then the “name” can be used at hist file by @name@! The “name” can be freely set.\n​ hist/ssd/ssd.yaml hist/ssd/ssd.yaml anchor: - \u0026energy [\"@name@.fCharge\",100,0.,100.] - \u0026timing [\"@name@.fTiming\",100,0.,100.] alias: energy_cut: @name@.fCharge\u003e1.0; group: - name: ssd_test title: ssd_test contents: - name: ssd_energy title: ssd_energy x: *energy - name: ssd_timing title: ssd_timing x: *timing - name: ssd_energy and timing title: ssd_energy and timing x: *timing y: *energy cut: energy_cut This is useful when there are more objects to check!\n​ chkssd.yaml chkssd.yaml # -- snip -- - include: ssd/ssd_single.yaml # Histogram - name: projection_ssd type: art::TTreeProjectionProcessor parameter: FileName: hist/ssd/ssd.yaml Type: art::TTreeProjection OutputFilename: *histout Replace: | name: ssd_cal - name: projection_ssd type: art::TTreeProjectionProcessor parameter: FileName: hist/ssd/ssd.yaml Type: art::TTreeProjection Replace: | name: ssd_raw # and so on! # -- snip -- File splitting using “include” nodes, as described in the section on steeling, can also be used in the same way.\n",
    "description": "",
    "tags": [],
    "title": "Histograms",
    "uri": "/artemis_crib/setting/histograms/index.html"
  },
  {
    "breadcrumb": "Installation",
    "content": "last modified: 2023-11-05 by Kodai Okawa Some CRIB-specific files use energy loss libraries. In particular, a library called SRIMlib has been developed by Okawa and some processors need to load this library.\ngit clone https://github.com/okawak/SRIMlib.git cd SRIMlib mkdir build cd build cmake .. make make installBefore using this library, you need to make database file (just .root file)\ncd .. source thisSRIMlib.sh updateIf you want to make energy loss figures, “f” option will work.\nupdate -fAlso, I recommend to write source thisSRIMlib.sh part in the .bashrc/.zshrc to load this library.\n",
    "description": "",
    "tags": [
      "CRIB"
    ],
    "title": "energyloss calculator",
    "uri": "/artemis_crib/installation/energyloss_calculator/index.html"
  },
  {
    "breadcrumb": "Example \u003e Online analysis",
    "content": "last modified: 2024-01-17 by Kodai Okawa It is very important to select events for online analysis as well. There are several options to do so, and I will cover all of them. If you know other useful way, please let me know.\nHistogram definition TCutG object TGateStopProcessor For clearer understanding, we will use this figure, and we call this as default figure:\nHistogram definition We explained in the Histograms page, but again we describe about histogram definition focus on the cut part.\nThe default figure defined like this:\n​ hist/f2/f2.yaml hist/f2/f2.yaml anchor: - \u0026f2ppacx [\"f2ppac.fX\",200,-50.,50.] - \u0026f2ppacy [\"f2ppac.fY\",200,-50.,50.] alias: group: - name: f2check title: f2_check contents: - name: f2PPAC X vs Y title: f2ppac X vs Y x: *f2ppacx y: *f2ppacy For example, let’s add the gate to select only “-10.0 \u003c X \u003c 10.0”. We can use alias node to define that.\n​ hist/f2/f2.yaml hist/f2/f2.yaml anchor: - \u0026f2ppacx [\"f2ppac.fX\",200,-50.,50.] - \u0026f2ppacy [\"f2ppac.fY\",200,-50.,50.] alias: centerx: abs(f2ppac.fX) \u003c 10.0; group: - name: f2check title: f2_check contents: - name: f2PPAC X vs Y{centerx} title: f2ppac X vs Y{centerx} x: *f2ppacx y: *f2ppacy cut: centerx Then the following histogram is created.\nAlso, multiple conditions can be specified at the same time.\n​ hist/f2/f2.yaml hist/f2/f2.yaml anchor: - \u0026f2ppacx [\"f2ppac.fX\",200,-50.,50.] - \u0026f2ppacy [\"f2ppac.fY\",200,-50.,50.] alias: centerx: abs(f2ppac.fX) \u003c 10.0; centery: abs(f2ppac.fY) \u003c 10.0; group: - name: f2check title: f2_check contents: - name: f2PPAC X vs Y{centerx \u0026\u0026 centery} title: f2ppac X vs Y{centerx \u0026\u0026 centery} x: *f2ppacx y: *f2ppacy cut: centerx \u0026\u0026 centery TCutG object We can also use TCutG object to select the event. As in new commands page, let’s assume we create this TCutG ROOT file by tcutg command. And the ROOT file and TCutG object name is f2star.\nIf you want to use this object to select event, just add this line is fine, as long as you use userlogon.C.\n​ hist/f2/f2.yaml hist/f2/f2.yaml anchor: - \u0026f2ppacx [\"f2ppac.fX\",200,-50.,50.] - \u0026f2ppacy [\"f2ppac.fY\",200,-50.,50.] alias: group: - name: f2check title: f2_check contents: - name: f2PPAC X vs Y{f2star} title: f2ppac X vs Y{f2star} x: *f2ppacx y: *f2ppacy cut: f2star Of course we can use in “tree-\u003eDraw()” because this TCutG objects are automatically loaded. The following sentence generate the same figure.\nartemis [] fcd 0 artemis [] zo artemis [] tree-\u003eDraw(\"f2ppac.fY:f2ppac.fX\u003e\u003e(200,-50.,50., 200,-50.,50.)\",\"f2star\",\"colz\")TGateStopProcessor The method used until now was to process just histograms and analyze them for all events in the event loop. If you know which events you don’t want, there are processors that allow you to skip the event loop under certain conditions. This may speed up the event loop.\nFor example. when we want to analyze only beam single event (it means the events are not coincident with SSD, and let’s suppose that condition is given by single.fID==0), let’s prepare the steering file.\n​ steering/gate/coin.yaml steering/gate/coin.yaml Processor: - name: proc_gateinit type: art::TGateArrayInitializer parameter: OutputTransparency: 1 - name: proc_gate type: art::TTreeFormulaGateProcessor parameter: Definitions: - \"beam_single; single.fID==0\" OutputTransparency: 1 Verbose: 1 - name: beam_single_gate type: art::TGateStopProcessor parameter: GateName: beam_single OutputTransparency: 1 StopIf: 0 Verbose: 1 To use TGateStopProcessor, we need to initialize the “gate” array object, so the first art::TGateArrayInitializer is needed. In the second processor, art::TTreeFormulaGateProcessor, we define the gate condition.\nThen the art::TGateStopProcessor judges the event is skipped or not. In the case of StopIf: 0, artemis ignore the event that the condition become false. In other words, StopIf: 0 means artemis will analyze the event only when the condition is true.\nThen, including this yaml file to the main steering file, you can check only the selected events.\n​ steering/hoge.yaml steering/hoge.yaml Anchor: - \u0026input ridf/@NAME@@NUM@.ridf - \u0026output output/@NAME@/@NUM@/hoge@NAME@@NUM@.root - \u0026histout output/@NAME@/@NUM@/hoge@NAME@@NUM@.hist.root Processor: - name: timer type: art::TTimerProcessor - name: ridf type: art::TRIDFEventStore parameter: OutputTransparency: 1 InputFiles: - *input SHMID: 0 - name: mapper type: art::TMappingProcessor parameter: OutputTransparency: 1 # include some other steering files - include: gate/coin.yaml - name: outputtree type: art::TOutputTreeProcessor parameter: FileName: - *output Info We didn’t check if we can use the TCutG object in this process…\n",
    "description": "",
    "tags": [],
    "title": "Gate",
    "uri": "/artemis_crib/example/online_analysis/gate/index.html"
  },
  {
    "breadcrumb": "Example \u003e Preparation",
    "content": "last modified: 2023-12-15 by Kodai Okawa ",
    "description": "",
    "tags": [],
    "title": "Set parameters",
    "uri": "/artemis_crib/example/preparation/set_parameter/index.html"
  },
  {
    "breadcrumb": "Setting",
    "content": "last modified: 2023-11-15 by Kodai Okawa When we start the analysis, there are many situations where the analysis server on which artemis is installed is not only operated directly, but also remotely using “ssh”. In such cases, there are various settings that need to be made in order for the figure to be displayed on the local computer, and some of these methods are described in this section. We recommended to use VNC server currently, but note that policies may change in the future.\nThis is a list of ways to display the figures.\nX11Forwarding VNC server Save figure and check by using VScode Web browser (THttpServer) X11Forwarding This is the simplest method. Simply transfer the remote X to the local.\n​ your local PC your local PC ssh -X analysisPC This “X” option allow the X11Forwarding.\nHowever, the problem with this method is that it takes a long time to process, and it takes longer from the time the command is typed until it is drawn. It is also not recommended as the process can become slow if a large number of people use it at the same time.\nHowever, it is simpler than other methods and should be used when necessary, e.g. for debugging.\nVNC server Info This is old version of VNC server (TigerVNC). Latest version supports more secure method, so this method may no longer be avaliable in the future…\nFirst please install VNC viewer to your PC. Any viewer may work well, but we are using this software.\nFirst, please check the ID number of the VNC server we are running.\n​ in analysis PC in analysis PC \u003e vncserver -list TigerVNC server sessions: X DISPLAY #\tPROCESS ID :1\t3146 :5\t7561 :2022\t29499 :2\t23055 In this example, number 1, 5, 2022 and 2 VNC server is running. And select an available number to start the VNC server you want to use.\n​ in analysis PC in analysis PC \u003e vncserver :10 # start the VNC server! If you want to kill the VNC server, the below command will work.\n​ in analysis PC in analysis PC \u003e vncserver -kill :10 # kill the VNC server! Next, configure the canvas created by artemis to be sent to a VNC server. The a command can treat this process by using .vncdisplay file!\n​ in analysis PC in analysis PC \u003e artlogin (username) # move to your artemis work directory \u003e echo \"10\" \u003e .vncdisplay # write the ID of VNC server to the .vncdisplay file Then, the setting in analysis PC is completed! The next step is to set up your local PC to receive this.\nInfo If you connect your PC in the same network with analysis PC, you can directory connect using the VNC viewer. However, CRIB analysis PC are connected CNS local network. In order to connect from outside network, we need to use “CNS login server”. If you want to make the login server account, please contact the CRIB member!\nIn this section, we are assuming that you have a CNS login server account.\nTo access the analysis PC, use two-stage ssh. Prepare the following configuration file.\n​ in local PC, .ssh/config in local PC, .ssh/config Host login # need to change HostName CNS_loginserver_hostname User username IdentityFile ~/.ssh/id_rsa # no need to change (if you want) ForWardX11Timeout 24h ControlPersist 30m ForwardAgent yes ControlMaster auto ControlPath ~/.ssh/mux-%r@%h:%p # any name is okay Host analysis # need to change HostName analysisPC_hostname User username IdentityFile ~/.ssh/id_rsa # no need to change (if you want) ProxyCommand ssh login nc %h %p ForwardAgent yes ControlMaster auto ControlPath ~/.ssh/mux-%r@%h:%p ControlPersist 30m Then you can access to the analysis PC simply by:\n​ in local PC in local PC \u003e ssh analysis Next, in order to receive from the VNC server, we use port-forwarding! VNC servers with ID x use port number 5900+x. For example if we use number “10”, the port will be 5910.\nForward this to a certain port on localhost. This number can be any number that is not in use.\n--- title: An example of port-forwarding --- graph LR; A(analysis PC\u003cbr\u003e\u003c/br\u003eport 5910) --\u003e |send|B(local PC\u003cbr\u003e\u003c/br\u003eport 55910) ​ in local PC, .ssh/config in local PC, .ssh/config Host analysis HostName analysisPC_hostname User username IdentityFile ~/.ssh/id_rsa LocalForward 55910 localhost:5910 ProxyCommand ssh login nc %h %p ForwardAgent yes ControlMaster auto ControlPath ~/.ssh/mux-%r@%h:%p ControlPersist 30m This allows you to display a VNC display by accessing port 55910 on your own PC (localhost), instead of having to access port 5910 on the analysis PC!\nIf your PC is in the same network, changing “localhost” to the “IP address of analysis PC” is okay (ex. 192.168.1.10:5910).\nSave figure and check by using VScode VScode is very exciting editor! The extension supports ssh and allows remote png files to be displayed on the editor.\nHowever, it is a bit time-consuming as the diagram has to be saved each time to view it. Please refer to this as one method.\nWeb browser (THttpServer) This is option…\nNow the histogram object cannot display by JSROOT, because the object is not actually “TH1” or “TH2” object but “TH1FTreeProj” or “TH2FTreeProj”. (ref: issue#40)\nWe can only display the “TCanvas” Object.\n",
    "description": "",
    "tags": [],
    "title": "VNC server",
    "uri": "/artemis_crib/setting/vncserver/index.html"
  },
  {
    "breadcrumb": "Installation",
    "content": "last modified: 2023-11-14 by Kodai Okawa With this command, all initial settings of “art_analysis” are made.\ncurl --proto '=https' --tlsv1.2 -sSf https://okawak.github.io/artemis_crib/bin/init.sh | shAfter that, please add the following lines to the .bashrc/.zshrc.\n​ .bashrc/.zshrc .bashrc/.zshrc # this is option source ${HOME}/Cern/root/root_install/bin/thisroot.sh \u0026\u003e /dev/null source ${HOME}/repos/artemis/install/bin/thisartemis.sh \u0026\u003e /dev/null source ${HOME}/repos/SRIMlib/thisSRIMlib.sh \u0026\u003e /dev/null # need from this line! export EXP_NAME=\"expname\" # your experiment export EXP_NAME_OLD=\"expname\" # this is option export PATH=\"${HOME}/art_analysis/bin:${PATH}\" source ${HOME}/art_analysis/bin/art_setting -q The setting is all!\nThen, the following commands (shellscript) will be downloaded.\nartlogin.sh This is loaded when you command artlogin. This command is described in the next chapter.\nartnew With this command, new artemis environment will be created interactively.\nart_setting This is like a library. The shellscript function artlogin, a etc. are written.\nart_check Checking these shellscript is updatable or not.\n",
    "description": "",
    "tags": [
      "CRIB",
      "unsettled"
    ],
    "title": "art_analysis",
    "uri": "/artemis_crib/installation/art_analysis/index.html"
  },
  {
    "breadcrumb": "Example \u003e Online analysis",
    "content": "last modified: 2023-12-20 by Kodai Okawa ",
    "description": "",
    "tags": [],
    "title": "Shifter task",
    "uri": "/artemis_crib/example/online_analysis/shift/index.html"
  },
  {
    "breadcrumb": "Example \u003e Preparation",
    "content": "last modified: 2023-12-20 by Kodai Okawa Analysis files for each experiment are managed using git. This is so that they can be quickly restored if they are all lost for some reason.\nGit is a bit complicated and you can commit freely if you are knowledgeable, but if you are unfamiliar with it, you don’t have to worry too much. The main use is that if someone creates a useful file, it will be reflected for each user as well.\nHere is a brief description of how to use it.\nDirectory structure In the CRIB analysis PC, we used local repository. The files related the repository is stored here.\n\u003e cd ~ \u003e tree -L 1 repos/exp repos/exp ├── he6p2024.git ├── he6p.git └── o14a.git # 2023/12/18 current status Warning Note that if you delete the files in this directory, you will lose all backups.\nbasic commands I will describe the most commonly used commands and how to resolve conflicts.\n",
    "description": "",
    "tags": [],
    "title": "Git",
    "uri": "/artemis_crib/example/preparation/git/index.html"
  },
  {
    "breadcrumb": "Example \u003e Offline analysis",
    "content": "last modified: 2023-12-15 by Kodai Okawa ",
    "description": "",
    "tags": [],
    "title": "Merge files",
    "uri": "/artemis_crib/example/offline_analysis/merge_files/index.html"
  },
  {
    "breadcrumb": "Example \u003e Online analysis",
    "content": "last modified: 2023-12-20 by Kodai Okawa ",
    "description": "",
    "tags": [],
    "title": "Scaler",
    "uri": "/artemis_crib/example/online_analysis/scaler/index.html"
  },
  {
    "breadcrumb": "Example \u003e Online analysis",
    "content": "last modified: 2023-12-15 by Kodai Okawa ",
    "description": "",
    "tags": [],
    "title": "Timestamp",
    "uri": "/artemis_crib/example/online_analysis/timestamp/index.html"
  },
  {
    "breadcrumb": "Example",
    "content": "This section explain the example of preparation by using some useful macro.\nBasic Tref for V1190 PPAC calibration MWDC calibration Alpha calibration MUX calibration Set parameters Git ",
    "description": "",
    "tags": null,
    "title": "Preparation",
    "uri": "/artemis_crib/example/preparation/index.html"
  },
  {
    "breadcrumb": "Example \u003e Online analysis",
    "content": "last modified: 2024-01-11 by Kodai Okawa Artemis produces mainly TArtTree and the branches are TClonesArray(art::hoge). It means that all objects rely on the artemis library, and we cannot open and check the data by using normal ROOT.\nAlso, sometimes it is necessary top check the raw data obtained by ADC and TDC as it is. Of course, the real raw data is binary and therefore difficult to read, so we will check the raw data after the decoders.\nRelated processors;\nTSegmentOutputProcessor.cc TModuleData.cc TSegmentCheckProcessor.cc (in original artemis source) How to check the raw data 1. prepare conf files We already prepared conf/map files, but in this case, we need to prepare conf/seg files. There are two files. This is an example, so please change it according to the experimental conditions.\n​ conf/seg/modulelist.yaml conf/seg/modulelist.yaml #modulename: # id: module id (it is module-specific) # ch: channel number # values: # - name1: [Nbin: int, min: double, max: double] it is for 2D histogram (these values vs. ch) # - name2: [Nbin: int, min: double, max: double] \u003c= somehow two line needed...? MADC32: id: 32 ch: 32 values: - adc: [4000, 0., 4000.] - tdc: [4000, 0., 4000.] # no use, but seems it needed... V1190A: id: 24 ch: 128 values: - tdcL: [300, -5000., 300000.] - tdcT: [300, -5000., 300000.] The module id list is here.\n​ conf/seg/seglist.yaml conf/seg/seglist.yaml #segment_name: # segid: [[dev], [fp], [det]] \u003c= same as a map file # type: V7XX \u003c= defined type in modulelist.yaml # modules: # - id: geo1 # - id: geo2 V1190: segid: [12, 0, 7] type: V1190A modules: - id: 0 - id: 1 MADC: segid: [12, 1, 6] type: MADC32 modules: - id: 0 - id: 1 - id: 2 2. use “steering/chkseg.yaml” Based on these two conf file, the steering/chkseg.yaml file produce rawdata histograms and TTree object. We can use steering/chkseg.yaml without any change I think.\nThis is an example from one CRIB experiment.\n$ a artemis [0] add steering/chkseg.yaml NAME=hoge NUM=0000 artemis [1] res artemis [2] sus artemis [3] ls artemis \u003e 0 TDirectory SegmentHistogram art::TSegmentCheckProcessor artemis [4] cd 0 artemis [5] ls SegmentHistogram \u003e 0 TDirectory E7_V1190 E7_V1190 1 TDirectory J1_V785 J1_V785 2 TDirectory J1_MADC J1_MADC 3 TDirectory J1_V1190 J1_V1190 artemis [6] cd 0 artemis [7] ls E7_V1190 \u003e 0 TH2F E7_V1190_0_tdcL E7_V1190_0_tdcL 1 TH2F E7_V1190_0_tdcT E7_V1190_0_tdcT 2 TH2F E7_V1190_1_tdcL E7_V1190_1_tdcL 3 TH2F E7_V1190_1_tdcT E7_V1190_1_tdcT # we can check these histograms by ht command artemis [8] fcd 0 artemis [9] br E7_V1190_0 vector\u003cvector\u003cint\u003e \u003e E7_V1190_1 vector\u003cvector\u003cint\u003e \u003e J1_V785_0 vector\u003cint\u003e J1_V785_1 vector\u003cint\u003e J1_V785_2 vector\u003cint\u003e J1_MADC_3 vector\u003cint\u003e J1_MADC_4 vector\u003cint\u003e J1_MADC_5 vector\u003cint\u003e J1_V1190_0 vector\u003cvector\u003cint\u003e \u003e Info If the module ID = 24 or 25, it is multihit TDC, so the branch become 2D vector. When you want to use std::vector method, you can use by “@” like\nartemis [*] tree-\u003eDraw(\"J1_V785_0@.size()\") Of course we can open this output ROOT file from normal ROOT.\n",
    "description": "",
    "tags": [],
    "title": "Check raw data",
    "uri": "/artemis_crib/example/online_analysis/check_rawdata/index.html"
  },
  {
    "breadcrumb": "Example",
    "content": "This section explain the example of the online analysis in the CRIB experiment.\nF1 Beam PID F2 PPAC MWDC SSD F3 Gate Shifter task Scaler Timestamp Check raw data ",
    "description": "",
    "tags": null,
    "title": "Online analysis",
    "uri": "/artemis_crib/example/online_analysis/index.html"
  },
  {
    "breadcrumb": "Example",
    "content": "This section explain the example of the offline analysis (some useful processors).\nNew processors Merge files Python environment pyROOT ",
    "description": "",
    "tags": null,
    "title": "Offline analysis",
    "uri": "/artemis_crib/example/offline_analysis/index.html"
  },
  {
    "breadcrumb": "Example",
    "content": "This section explain the example of the Monte Carlo simulation by using artemis.\nBeam_generator Nbodyreaction Geometry Detect_particle Solidangle ",
    "description": "",
    "tags": null,
    "title": "MC Simulation",
    "uri": "/artemis_crib/example/simulation/index.html"
  },
  {
    "breadcrumb": "Example \u003e Offline analysis",
    "content": "last modified: 2023-12-15 by Kodai Okawa ",
    "description": "",
    "tags": [],
    "title": "Python environment",
    "uri": "/artemis_crib/example/offline_analysis/python_environment/index.html"
  },
  {
    "breadcrumb": "Example \u003e Offline analysis",
    "content": "last modified: 2023-12-15 by Kodai Okawa ",
    "description": "",
    "tags": [],
    "title": "pyROOT",
    "uri": "/artemis_crib/example/offline_analysis/pyroot/index.html"
  },
  {
    "breadcrumb": "CRIB Configuration",
    "content": "last modified: 2024-01-11 by Kodai Okawa thisartemis.sh.in Grammar issue I think.\n​ artemis/sources/main/thisartemis.sh.in artemis/sources/main/thisartemis.sh.in export LD_LIBRARY_PATH=$TARTSYS/lib:$LD_LIBRARY_PATH -if [ \"@BUILD_GET@\" == \"ON\" ]; then +if [[ \"@BUILD_GET@\" == \"ON\" ]]; then export LD_LIBRARY_PATH=@GET_LIB_DIR@:$LD_LIBRARY_PATH fi -if [ \"@MPI_CXX_FOUND@\" == \"TRUE\" ]; then +if [[ \"@MPI_CXX_FOUND@\" == \"TRUE\" ]]; then dir=@MPI_CXX_LIBRARIES@ libdir=\"$(dirname $dir)\" xval command Add cross hair.\n​ artemis/sources/commands/TCatCmdXval.cc artemis/sources/commands/TCatCmdXval.cc 84 void TCatCmdXval::GetEvent() 85 { 86+ dynamic_cast\u003cTPad *\u003e(gPad)-\u003eDrawCrosshair(); 87 const int event = gPad-\u003eGetEvent(); pr (projection) command After the command, the projected histogram will automatically be displayed.\n​ artemis/sources/commands/TCatCmdPr.cc artemis/sources/commands/TCatCmdPr.cc 55 if (!obj-\u003eInheritsFrom(TH2::Class())) { 56 // TArtCore::Info(\"TCatCmdPr::Run\",\"%s is not 2D histogram\", 57 // obj-\u003eGetName()); 58+ Info(\"Run\", \"%s is not 2D histogram\", obj-\u003eGetName()); 59 continue; 60 } 61+ Int_t nid = (gDirectory-\u003eGetList())-\u003eGetEntries(); 62 Run((TH2*) obj, opt); 63+ Info(\"Run\", \"id = %d hist is created\", nid); 64+ TCatHistManager::Instance()-\u003eDrawObject(nid); 65 } 66 return 1; 67 } TModuleInfo class In the CRIB processor, there is a processor that inherits from TModuleInfo, TModuleData. In the constractor of this class use copy constractor of TModuleInfo, but the default artemis doesn’t implement it. This class is used when we want to check the raw data. For the detail, please see check raw data page.\nTherefore, we modified this like this:\n​ artemis/sources/loop/TModuleInfo.cc artemis/sources/loop/TModuleInfo.cc 31 TModuleInfo::TModuleInfo(const TModuleInfo\u0026 rhs) 32+ : TParameterObject(rhs), 33+ fID(rhs.fID), 34+ fType(rhs.fType), 35+ fHists(nullptr) 36 { 37+ if (rhs.fHist) { 38+ fHists = new TObjArray(*(rhs.fHists)); 39+ } 40+ 41+ fRanges = rhs.fRanges; 42 } ",
    "description": "",
    "tags": [
      "CRIB"
    ],
    "title": "Minor changes",
    "uri": "/artemis_crib/crib_parts/minor_change/index.html"
  },
  {
    "breadcrumb": "Example \u003e MC Simulation",
    "content": "last modified: 2023-09-29 by Kodai Okawa The previous sections have described how to loop events from a ridf file or root file, but now I will describe how to generate events to use as a simulation.\nRequirements:\nsrc-crib/simulation/TRandomBeamGenerator src-crib/simulation/TTreeBeamGenerator src-crib/simulation/TParticleInfo As you know, an “event store” must be used to analyse the event loop. For example, in the online analysis, we used TRIDFEventStore, and in the offline analysis, we used TTreeEventStore.\nBut when we want to simulate something, there are no data file. In that case, we can use TCounterEventStore or TRandomNumberEventStore.\nTCounterEventStore: generate numbers in sequence from 0 to N. TRandomNumberEventStore: generate number from 0.0 to 1.0 randomly. Here I will simply describe a simulation using TCounterEventStore.\nInfo As I explained in CRIB_parts before, in the current artemis version, the TCounterEventStore does not seem to be recognised as EventStore. So if we use this EventStore, “no event store” comments will output. I don’t think it makes problem, so it is okay comment out the part of TLoop.cc that prints “no event store”. (Possibly a problem with your environment).\n",
    "description": "",
    "tags": [],
    "title": "Beam_generator",
    "uri": "/artemis_crib/example/simulation/beam_generator/index.html"
  },
  {
    "breadcrumb": "Example \u003e MC Simulation",
    "content": "last modified: 2023-09-29 by Kodai Okawa ",
    "description": "",
    "tags": [],
    "title": "Nbodyreaction",
    "uri": "/artemis_crib/example/simulation/nbodyreaction/index.html"
  },
  {
    "breadcrumb": "Example \u003e MC Simulation",
    "content": "last modified: 2023-09-29 by Kodai Okawa In this page, I will explain how to determine the detecter geometry configration.\nRequirement:\nsrc-crib/geo/TUserGeoInitializer src-crib/geo/TDetectorParameter Firstly, let’s prepare the parameter file like this:\n​ prm/geo/example.yaml prm/geo/example.yaml material: - name: Vaccum # id=0 atomic_mass: 0.0 atomic_num: 0.0 density: 0.0 # g/cm3 - name: Si # id=1 atomic_mass: 28.084 atomic_num: 14.0 density: 2.321 # Note: beam axis -\u003e z, upper direction -\u003e y conposition: detector: - name: tel1 strip: [16, 16] center_rotation: [0., 0., 322.0] # mm offset: [0., 0., 0.] distance: 244.0 angle: -4.0 # deg thickness: [0.02, 0.301, 1.494, 1.486] material: [Si] - name: tel2 strip: [16, 16] center_rotation: [0., 0., 322.0] offset: [0., 0., 0.] distance: 154.5 angle: 27.0 thickness: [0.02, 0.300, 1.494, 1.485] material: [Si] volume: top: # detector world name: TOP type: box # now only box is available material: 0 size: [400.0, 200.0, 1288.0] # mm detector: - name: tel1 type: box material: 1 size: [50.0, 50.0, 1.0] # mm - name: tel2 type: box material: 1 size: [50.0, 50.0, 1.0] # mm There are many components to explain! The material node is used to define TGeoMaterial and TGeoMedium classes. (But they are not directly used.) From name to density node are used to make a instance of this object. This values are not used in the current processors.\nThe next conposition node define the detector configuration! General telescopes of the CRIB experiment consist of DSSSD and SSD (single-pad), and the node below defines the SSD of the telescope.\nname: Name of the telescope. For example tel1, tel2, and so on. strip: X x Y strip number. It is defined as an array like [16, 32], this means X:16 strips and Y:32 strips thickness: Thickness of the each layer. If there are two layer, the size of the array become two. You can add to any size. The unit is mm. material: material of the each layer. The string is used in SRIMlib calculation. This node is defined as a array for each layer, but if it is one, the same material is applied. For example, in example.yaml, [Si] means [Si, Si, Si, Si]. (You need to prepare SRIMlib setting beforehand!) Let’s move on to the geometry part! The node is center_rotation, offset, distance and angle. Please look at this figure.\nPlease not that the center_rotation and offset are defined in (x, y, z) coordinate (-\u003e [x, y, z]), but distance and angle is scalar value. The unit of length is mm, angle is deg.\nInfo The sign of the angle is defined as positive at this figure. And generally, we set z=0 at target position. (For the gas target, we set 0 at window position.)\nThe last part is volume node! In this parts, the shape of the detector will be defined by using TGeoVolume class. The TGeoVolume needs name, type, material and size. For the type, I only prepared “box”. (It means the code use only vol-\u003eMakeBox method.)\nThe first top node must be set because it defined “detector world”. Generally, the material is okay to set vaccum. And the material is defined in the material node, and the id (the order) can be used. So the format is like material: 0. And the size is generally set to the size of the scattering chamber, but for the safety, it is okay to set larger number. Also the unit is mm and format is (x, y, z).\nNext, at the volume/detector node, we can define the detector size. Please NOTE that the name should be the same with conposition/detector/name node.\nThen, let’s check if the parameter file can be correctly used! Please prepare the steering file.\n​ steering/geo_example.yaml steering/geo_example.yaml Anchor: Processor: - name: detector_initialize type: art::TUserGeoInitializer parameter: Name: prm_detector FileName: prm/geo/example.yaml OutputTransparency: 1 This steering file doesn’t use event loop. Just we want to check the parameter file works well or not.\nThen let’s see in the artemis!\nacd a -- snip -- artemis [0] add steering/geo_example.yaml -- snip -- artemis [1] ls artemis \u003e 0 TGeoVolume TOP Top volume artemis [2]The detector geometry object is successfully generated! In order to check the object, please use draw command for example. (It is defined only in CRIB artemis, to draw not only histogram object. This is under development.)\nartemis [2] draw 0 The red box is the TOP, and the black boxes are detectors. If the detector is placed where you expect it to be, the parameters have been successfully set!\nIn the event loop process, if you want to use the detector geometry information, you can use prm_detector in the steering files. I will explain the next session!\n",
    "description": "",
    "tags": [],
    "title": "Geometry",
    "uri": "/artemis_crib/example/simulation/geometry/index.html"
  },
  {
    "breadcrumb": "Example \u003e MC Simulation",
    "content": "last modified: 2023-09-29 by Kodai Okawa ",
    "description": "",
    "tags": [],
    "title": "Detect_particle",
    "uri": "/artemis_crib/example/simulation/detect_particle/index.html"
  },
  {
    "breadcrumb": "Example \u003e MC Simulation",
    "content": "last modified: 2023-09-29 by KodaiOkawa Beam_generator Nbodyreaction Geometry Detect_particle As an application of the above four sections, I would like to explain how to calculate solid angles using Monte Carlo methods!\n",
    "description": "",
    "tags": [],
    "title": "Solidangle",
    "uri": "/artemis_crib/example/simulation/solidangle/index.html"
  },
  {
    "breadcrumb": "Tags",
    "content": "",
    "description": "",
    "tags": null,
    "title": "Tag :: CRIB",
    "uri": "/artemis_crib/tags/crib/index.html"
  },
  {
    "breadcrumb": "",
    "content": "",
    "description": "",
    "tags": null,
    "title": "Tags",
    "uri": "/artemis_crib/tags/index.html"
  },
  {
    "breadcrumb": "Tags",
    "content": "",
    "description": "",
    "tags": null,
    "title": "Tag :: unsettled",
    "uri": "/artemis_crib/tags/unsettled/index.html"
  },
  {
    "breadcrumb": "",
    "content": "",
    "description": "",
    "tags": null,
    "title": "Categories",
    "uri": "/artemis_crib/categories/index.html"
  }
]
